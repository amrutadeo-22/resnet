{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutadeo-22/resnet/blob/main/wide%2Baggre%2Bcbam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9kquyFqB7yk",
        "outputId": "c5baff82-4bd1-4e72-bc1f-52896ab4db03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train Epoch: 0 [0/50000] Loss: 2.348 | Acc: 10.156%\n",
            "Train Epoch: 0 [1280/50000] Loss: 2.271 | Acc: 15.767%\n",
            "Train Epoch: 0 [2560/50000] Loss: 2.173 | Acc: 20.015%\n",
            "Train Epoch: 0 [3840/50000] Loss: 2.105 | Acc: 21.951%\n",
            "Train Epoch: 0 [5120/50000] Loss: 2.058 | Acc: 23.571%\n",
            "Train Epoch: 0 [6400/50000] Loss: 2.018 | Acc: 24.341%\n",
            "Train Epoch: 0 [7680/50000] Loss: 1.991 | Acc: 25.231%\n",
            "Train Epoch: 0 [8960/50000] Loss: 1.968 | Acc: 25.825%\n",
            "Train Epoch: 0 [10240/50000] Loss: 1.945 | Acc: 26.698%\n",
            "Train Epoch: 0 [11520/50000] Loss: 1.922 | Acc: 27.370%\n",
            "Train Epoch: 0 [12800/50000] Loss: 1.889 | Acc: 28.566%\n",
            "Train Epoch: 0 [14080/50000] Loss: 1.864 | Acc: 29.695%\n",
            "Train Epoch: 0 [15360/50000] Loss: 1.846 | Acc: 30.269%\n",
            "Train Epoch: 0 [16640/50000] Loss: 1.831 | Acc: 31.095%\n",
            "Train Epoch: 0 [17920/50000] Loss: 1.814 | Acc: 31.782%\n",
            "Train Epoch: 0 [19200/50000] Loss: 1.798 | Acc: 32.342%\n",
            "Train Epoch: 0 [20480/50000] Loss: 1.785 | Acc: 32.808%\n",
            "Train Epoch: 0 [21760/50000] Loss: 1.773 | Acc: 33.329%\n",
            "Train Epoch: 0 [23040/50000] Loss: 1.758 | Acc: 34.008%\n",
            "Train Epoch: 0 [24320/50000] Loss: 1.745 | Acc: 34.612%\n",
            "Train Epoch: 0 [25600/50000] Loss: 1.732 | Acc: 35.121%\n",
            "Train Epoch: 0 [26880/50000] Loss: 1.718 | Acc: 35.645%\n",
            "Train Epoch: 0 [28160/50000] Loss: 1.704 | Acc: 36.206%\n",
            "Train Epoch: 0 [29440/50000] Loss: 1.690 | Acc: 36.675%\n",
            "Train Epoch: 0 [30720/50000] Loss: 1.678 | Acc: 37.169%\n",
            "Train Epoch: 0 [32000/50000] Loss: 1.666 | Acc: 37.662%\n",
            "Train Epoch: 0 [33280/50000] Loss: 1.654 | Acc: 38.135%\n",
            "Train Epoch: 0 [34560/50000] Loss: 1.643 | Acc: 38.650%\n",
            "Train Epoch: 0 [35840/50000] Loss: 1.632 | Acc: 39.088%\n",
            "Train Epoch: 0 [37120/50000] Loss: 1.620 | Acc: 39.591%\n",
            "Train Epoch: 0 [38400/50000] Loss: 1.612 | Acc: 39.922%\n",
            "Train Epoch: 0 [39680/50000] Loss: 1.601 | Acc: 40.336%\n",
            "Train Epoch: 0 [40960/50000] Loss: 1.592 | Acc: 40.742%\n",
            "Train Epoch: 0 [42240/50000] Loss: 1.583 | Acc: 41.123%\n",
            "Train Epoch: 0 [43520/50000] Loss: 1.572 | Acc: 41.525%\n",
            "Train Epoch: 0 [44800/50000] Loss: 1.562 | Acc: 41.960%\n",
            "Train Epoch: 0 [46080/50000] Loss: 1.553 | Acc: 42.328%\n",
            "Train Epoch: 0 [47360/50000] Loss: 1.545 | Acc: 42.687%\n",
            "Train Epoch: 0 [48640/50000] Loss: 1.535 | Acc: 43.116%\n",
            "Train Epoch: 0 [31200/50000] Loss: 1.527 | Acc: 43.428%\n",
            "Test Epoch: 0 | Loss: 1.356 | Acc: 51.620%\n",
            "Train Epoch: 1 [0/50000] Loss: 1.087 | Acc: 58.594%\n",
            "Train Epoch: 1 [1280/50000] Loss: 1.193 | Acc: 55.824%\n",
            "Train Epoch: 1 [2560/50000] Loss: 1.171 | Acc: 56.548%\n",
            "Train Epoch: 1 [3840/50000] Loss: 1.156 | Acc: 57.359%\n",
            "Train Epoch: 1 [5120/50000] Loss: 1.150 | Acc: 57.755%\n",
            "Train Epoch: 1 [6400/50000] Loss: 1.147 | Acc: 58.119%\n",
            "Train Epoch: 1 [7680/50000] Loss: 1.144 | Acc: 58.645%\n",
            "Train Epoch: 1 [8960/50000] Loss: 1.146 | Acc: 58.638%\n",
            "Train Epoch: 1 [10240/50000] Loss: 1.144 | Acc: 58.594%\n",
            "Train Epoch: 1 [11520/50000] Loss: 1.146 | Acc: 58.508%\n",
            "Train Epoch: 1 [12800/50000] Loss: 1.143 | Acc: 58.555%\n",
            "Train Epoch: 1 [14080/50000] Loss: 1.137 | Acc: 58.903%\n",
            "Train Epoch: 1 [15360/50000] Loss: 1.133 | Acc: 59.020%\n",
            "Train Epoch: 1 [16640/50000] Loss: 1.133 | Acc: 58.999%\n",
            "Train Epoch: 1 [17920/50000] Loss: 1.127 | Acc: 59.292%\n",
            "Train Epoch: 1 [19200/50000] Loss: 1.130 | Acc: 59.158%\n",
            "Train Epoch: 1 [20480/50000] Loss: 1.126 | Acc: 59.307%\n",
            "Train Epoch: 1 [21760/50000] Loss: 1.122 | Acc: 59.471%\n",
            "Train Epoch: 1 [23040/50000] Loss: 1.118 | Acc: 59.690%\n",
            "Train Epoch: 1 [24320/50000] Loss: 1.115 | Acc: 59.845%\n",
            "Train Epoch: 1 [25600/50000] Loss: 1.113 | Acc: 59.892%\n",
            "Train Epoch: 1 [26880/50000] Loss: 1.109 | Acc: 59.993%\n",
            "Train Epoch: 1 [28160/50000] Loss: 1.105 | Acc: 60.153%\n",
            "Train Epoch: 1 [29440/50000] Loss: 1.103 | Acc: 60.251%\n",
            "Train Epoch: 1 [30720/50000] Loss: 1.103 | Acc: 60.273%\n",
            "Train Epoch: 1 [32000/50000] Loss: 1.099 | Acc: 60.408%\n",
            "Train Epoch: 1 [33280/50000] Loss: 1.094 | Acc: 60.551%\n",
            "Train Epoch: 1 [34560/50000] Loss: 1.094 | Acc: 60.580%\n",
            "Train Epoch: 1 [35840/50000] Loss: 1.091 | Acc: 60.682%\n",
            "Train Epoch: 1 [37120/50000] Loss: 1.088 | Acc: 60.809%\n",
            "Train Epoch: 1 [38400/50000] Loss: 1.084 | Acc: 60.938%\n",
            "Train Epoch: 1 [39680/50000] Loss: 1.080 | Acc: 61.078%\n",
            "Train Epoch: 1 [40960/50000] Loss: 1.076 | Acc: 61.237%\n",
            "Train Epoch: 1 [42240/50000] Loss: 1.074 | Acc: 61.277%\n",
            "Train Epoch: 1 [43520/50000] Loss: 1.071 | Acc: 61.336%\n",
            "Train Epoch: 1 [44800/50000] Loss: 1.068 | Acc: 61.465%\n",
            "Train Epoch: 1 [46080/50000] Loss: 1.065 | Acc: 61.572%\n",
            "Train Epoch: 1 [47360/50000] Loss: 1.062 | Acc: 61.675%\n",
            "Train Epoch: 1 [48640/50000] Loss: 1.061 | Acc: 61.741%\n",
            "Train Epoch: 1 [31200/50000] Loss: 1.057 | Acc: 61.882%\n",
            "Test Epoch: 1 | Loss: 1.192 | Acc: 58.960%\n",
            "Train Epoch: 2 [0/50000] Loss: 0.993 | Acc: 64.844%\n",
            "Train Epoch: 2 [1280/50000] Loss: 0.993 | Acc: 63.849%\n",
            "Train Epoch: 2 [2560/50000] Loss: 0.982 | Acc: 64.472%\n",
            "Train Epoch: 2 [3840/50000] Loss: 0.969 | Acc: 65.247%\n",
            "Train Epoch: 2 [5120/50000] Loss: 0.984 | Acc: 64.634%\n",
            "Train Epoch: 2 [6400/50000] Loss: 0.979 | Acc: 64.782%\n",
            "Train Epoch: 2 [7680/50000] Loss: 0.972 | Acc: 65.151%\n",
            "Train Epoch: 2 [8960/50000] Loss: 0.960 | Acc: 65.592%\n",
            "Train Epoch: 2 [10240/50000] Loss: 0.964 | Acc: 65.432%\n",
            "Train Epoch: 2 [11520/50000] Loss: 0.956 | Acc: 65.702%\n",
            "Train Epoch: 2 [12800/50000] Loss: 0.950 | Acc: 65.880%\n",
            "Train Epoch: 2 [14080/50000] Loss: 0.946 | Acc: 66.111%\n",
            "Train Epoch: 2 [15360/50000] Loss: 0.944 | Acc: 66.284%\n",
            "Train Epoch: 2 [16640/50000] Loss: 0.941 | Acc: 66.359%\n",
            "Train Epoch: 2 [17920/50000] Loss: 0.939 | Acc: 66.478%\n",
            "Train Epoch: 2 [19200/50000] Loss: 0.937 | Acc: 66.551%\n",
            "Train Epoch: 2 [20480/50000] Loss: 0.933 | Acc: 66.760%\n",
            "Train Epoch: 2 [21760/50000] Loss: 0.934 | Acc: 66.680%\n",
            "Train Epoch: 2 [23040/50000] Loss: 0.935 | Acc: 66.583%\n",
            "Train Epoch: 2 [24320/50000] Loss: 0.935 | Acc: 66.598%\n",
            "Train Epoch: 2 [25600/50000] Loss: 0.934 | Acc: 66.671%\n",
            "Train Epoch: 2 [26880/50000] Loss: 0.931 | Acc: 66.795%\n",
            "Train Epoch: 2 [28160/50000] Loss: 0.928 | Acc: 66.958%\n",
            "Train Epoch: 2 [29440/50000] Loss: 0.926 | Acc: 67.056%\n",
            "Train Epoch: 2 [30720/50000] Loss: 0.924 | Acc: 67.103%\n",
            "Train Epoch: 2 [32000/50000] Loss: 0.923 | Acc: 67.100%\n",
            "Train Epoch: 2 [33280/50000] Loss: 0.921 | Acc: 67.152%\n",
            "Train Epoch: 2 [34560/50000] Loss: 0.919 | Acc: 67.205%\n",
            "Train Epoch: 2 [35840/50000] Loss: 0.918 | Acc: 67.215%\n",
            "Train Epoch: 2 [37120/50000] Loss: 0.917 | Acc: 67.287%\n",
            "Train Epoch: 2 [38400/50000] Loss: 0.916 | Acc: 67.299%\n",
            "Train Epoch: 2 [39680/50000] Loss: 0.914 | Acc: 67.396%\n",
            "Train Epoch: 2 [40960/50000] Loss: 0.912 | Acc: 67.438%\n",
            "Train Epoch: 2 [42240/50000] Loss: 0.910 | Acc: 67.497%\n",
            "Train Epoch: 2 [43520/50000] Loss: 0.908 | Acc: 67.593%\n",
            "Train Epoch: 2 [44800/50000] Loss: 0.906 | Acc: 67.615%\n",
            "Train Epoch: 2 [46080/50000] Loss: 0.905 | Acc: 67.668%\n",
            "Train Epoch: 2 [47360/50000] Loss: 0.903 | Acc: 67.756%\n",
            "Train Epoch: 2 [48640/50000] Loss: 0.900 | Acc: 67.844%\n",
            "Train Epoch: 2 [31200/50000] Loss: 0.898 | Acc: 67.902%\n",
            "Test Epoch: 2 | Loss: 0.914 | Acc: 68.230%\n",
            "Train Epoch: 3 [0/50000] Loss: 0.819 | Acc: 71.875%\n",
            "Train Epoch: 3 [1280/50000] Loss: 0.744 | Acc: 74.361%\n",
            "Train Epoch: 3 [2560/50000] Loss: 0.744 | Acc: 73.735%\n",
            "Train Epoch: 3 [3840/50000] Loss: 0.783 | Acc: 72.908%\n",
            "Train Epoch: 3 [5120/50000] Loss: 0.807 | Acc: 71.875%\n",
            "Train Epoch: 3 [6400/50000] Loss: 0.817 | Acc: 71.615%\n",
            "Train Epoch: 3 [7680/50000] Loss: 0.820 | Acc: 71.504%\n",
            "Train Epoch: 3 [8960/50000] Loss: 0.821 | Acc: 71.281%\n",
            "Train Epoch: 3 [10240/50000] Loss: 0.810 | Acc: 71.557%\n",
            "Train Epoch: 3 [11520/50000] Loss: 0.811 | Acc: 71.669%\n",
            "Train Epoch: 3 [12800/50000] Loss: 0.804 | Acc: 71.852%\n",
            "Train Epoch: 3 [14080/50000] Loss: 0.804 | Acc: 71.776%\n",
            "Train Epoch: 3 [15360/50000] Loss: 0.806 | Acc: 71.636%\n",
            "Train Epoch: 3 [16640/50000] Loss: 0.806 | Acc: 71.511%\n",
            "Train Epoch: 3 [17920/50000] Loss: 0.806 | Acc: 71.659%\n",
            "Train Epoch: 3 [19200/50000] Loss: 0.806 | Acc: 71.632%\n",
            "Train Epoch: 3 [20480/50000] Loss: 0.807 | Acc: 71.540%\n",
            "Train Epoch: 3 [21760/50000] Loss: 0.807 | Acc: 71.459%\n",
            "Train Epoch: 3 [23040/50000] Loss: 0.804 | Acc: 71.538%\n",
            "Train Epoch: 3 [24320/50000] Loss: 0.806 | Acc: 71.446%\n",
            "Train Epoch: 3 [25600/50000] Loss: 0.805 | Acc: 71.490%\n",
            "Train Epoch: 3 [26880/50000] Loss: 0.805 | Acc: 71.508%\n",
            "Train Epoch: 3 [28160/50000] Loss: 0.802 | Acc: 71.567%\n",
            "Train Epoch: 3 [29440/50000] Loss: 0.801 | Acc: 71.625%\n",
            "Train Epoch: 3 [30720/50000] Loss: 0.802 | Acc: 71.629%\n",
            "Train Epoch: 3 [32000/50000] Loss: 0.801 | Acc: 71.698%\n",
            "Train Epoch: 3 [33280/50000] Loss: 0.799 | Acc: 71.719%\n",
            "Train Epoch: 3 [34560/50000] Loss: 0.798 | Acc: 71.780%\n",
            "Train Epoch: 3 [35840/50000] Loss: 0.796 | Acc: 71.844%\n",
            "Train Epoch: 3 [37120/50000] Loss: 0.794 | Acc: 71.988%\n",
            "Train Epoch: 3 [38400/50000] Loss: 0.791 | Acc: 72.067%\n",
            "Train Epoch: 3 [39680/50000] Loss: 0.791 | Acc: 72.136%\n",
            "Train Epoch: 3 [40960/50000] Loss: 0.787 | Acc: 72.272%\n",
            "Train Epoch: 3 [42240/50000] Loss: 0.787 | Acc: 72.293%\n",
            "Train Epoch: 3 [43520/50000] Loss: 0.786 | Acc: 72.340%\n",
            "Train Epoch: 3 [44800/50000] Loss: 0.784 | Acc: 72.380%\n",
            "Train Epoch: 3 [46080/50000] Loss: 0.784 | Acc: 72.414%\n",
            "Train Epoch: 3 [47360/50000] Loss: 0.782 | Acc: 72.496%\n",
            "Train Epoch: 3 [48640/50000] Loss: 0.780 | Acc: 72.519%\n",
            "Train Epoch: 3 [31200/50000] Loss: 0.779 | Acc: 72.564%\n",
            "Test Epoch: 3 | Loss: 0.835 | Acc: 71.260%\n",
            "Train Epoch: 4 [0/50000] Loss: 0.695 | Acc: 76.562%\n",
            "Train Epoch: 4 [1280/50000] Loss: 0.713 | Acc: 75.426%\n",
            "Train Epoch: 4 [2560/50000] Loss: 0.717 | Acc: 74.814%\n",
            "Train Epoch: 4 [3840/50000] Loss: 0.732 | Acc: 74.294%\n",
            "Train Epoch: 4 [5120/50000] Loss: 0.727 | Acc: 74.428%\n",
            "Train Epoch: 4 [6400/50000] Loss: 0.725 | Acc: 74.617%\n",
            "Train Epoch: 4 [7680/50000] Loss: 0.719 | Acc: 74.795%\n",
            "Train Epoch: 4 [8960/50000] Loss: 0.724 | Acc: 74.791%\n",
            "Train Epoch: 4 [10240/50000] Loss: 0.722 | Acc: 74.884%\n",
            "Train Epoch: 4 [11520/50000] Loss: 0.723 | Acc: 74.880%\n",
            "Train Epoch: 4 [12800/50000] Loss: 0.723 | Acc: 74.768%\n",
            "Train Epoch: 4 [14080/50000] Loss: 0.719 | Acc: 75.063%\n",
            "Train Epoch: 4 [15360/50000] Loss: 0.720 | Acc: 74.890%\n",
            "Train Epoch: 4 [16640/50000] Loss: 0.721 | Acc: 74.869%\n",
            "Train Epoch: 4 [17920/50000] Loss: 0.722 | Acc: 74.817%\n",
            "Train Epoch: 4 [19200/50000] Loss: 0.722 | Acc: 74.860%\n",
            "Train Epoch: 4 [20480/50000] Loss: 0.722 | Acc: 74.850%\n",
            "Train Epoch: 4 [21760/50000] Loss: 0.723 | Acc: 74.845%\n",
            "Train Epoch: 4 [23040/50000] Loss: 0.719 | Acc: 74.935%\n",
            "Train Epoch: 4 [24320/50000] Loss: 0.719 | Acc: 74.918%\n",
            "Train Epoch: 4 [25600/50000] Loss: 0.719 | Acc: 74.891%\n",
            "Train Epoch: 4 [26880/50000] Loss: 0.718 | Acc: 74.900%\n",
            "Train Epoch: 4 [28160/50000] Loss: 0.716 | Acc: 74.954%\n",
            "Train Epoch: 4 [29440/50000] Loss: 0.717 | Acc: 74.959%\n",
            "Train Epoch: 4 [30720/50000] Loss: 0.717 | Acc: 75.032%\n",
            "Train Epoch: 4 [32000/50000] Loss: 0.715 | Acc: 75.068%\n",
            "Train Epoch: 4 [33280/50000] Loss: 0.715 | Acc: 75.117%\n",
            "Train Epoch: 4 [34560/50000] Loss: 0.714 | Acc: 75.112%\n",
            "Train Epoch: 4 [35840/50000] Loss: 0.714 | Acc: 75.133%\n",
            "Train Epoch: 4 [37120/50000] Loss: 0.713 | Acc: 75.134%\n",
            "Train Epoch: 4 [38400/50000] Loss: 0.711 | Acc: 75.197%\n",
            "Train Epoch: 4 [39680/50000] Loss: 0.711 | Acc: 75.209%\n",
            "Train Epoch: 4 [40960/50000] Loss: 0.711 | Acc: 75.246%\n",
            "Train Epoch: 4 [42240/50000] Loss: 0.712 | Acc: 75.250%\n",
            "Train Epoch: 4 [43520/50000] Loss: 0.712 | Acc: 75.243%\n",
            "Train Epoch: 4 [44800/50000] Loss: 0.711 | Acc: 75.272%\n",
            "Train Epoch: 4 [46080/50000] Loss: 0.711 | Acc: 75.264%\n",
            "Train Epoch: 4 [47360/50000] Loss: 0.710 | Acc: 75.286%\n",
            "Train Epoch: 4 [48640/50000] Loss: 0.709 | Acc: 75.306%\n",
            "Train Epoch: 4 [31200/50000] Loss: 0.709 | Acc: 75.320%\n",
            "Test Epoch: 4 | Loss: 0.856 | Acc: 71.380%\n",
            "Train Epoch: 5 [0/50000] Loss: 0.654 | Acc: 80.469%\n",
            "Train Epoch: 5 [1280/50000] Loss: 0.643 | Acc: 77.131%\n",
            "Train Epoch: 5 [2560/50000] Loss: 0.672 | Acc: 76.004%\n",
            "Train Epoch: 5 [3840/50000] Loss: 0.667 | Acc: 76.663%\n",
            "Train Epoch: 5 [5120/50000] Loss: 0.657 | Acc: 76.944%\n",
            "Train Epoch: 5 [6400/50000] Loss: 0.660 | Acc: 76.991%\n",
            "Train Epoch: 5 [7680/50000] Loss: 0.662 | Acc: 76.998%\n",
            "Train Epoch: 5 [8960/50000] Loss: 0.661 | Acc: 76.981%\n",
            "Train Epoch: 5 [10240/50000] Loss: 0.660 | Acc: 77.132%\n",
            "Train Epoch: 5 [11520/50000] Loss: 0.660 | Acc: 77.155%\n",
            "Train Epoch: 5 [12800/50000] Loss: 0.665 | Acc: 77.019%\n",
            "Train Epoch: 5 [14080/50000] Loss: 0.667 | Acc: 76.872%\n",
            "Train Epoch: 5 [15360/50000] Loss: 0.669 | Acc: 76.821%\n",
            "Train Epoch: 5 [16640/50000] Loss: 0.669 | Acc: 76.867%\n",
            "Train Epoch: 5 [17920/50000] Loss: 0.670 | Acc: 76.817%\n",
            "Train Epoch: 5 [19200/50000] Loss: 0.672 | Acc: 76.738%\n",
            "Train Epoch: 5 [20480/50000] Loss: 0.670 | Acc: 76.805%\n",
            "Train Epoch: 5 [21760/50000] Loss: 0.672 | Acc: 76.713%\n",
            "Train Epoch: 5 [23040/50000] Loss: 0.672 | Acc: 76.701%\n",
            "Train Epoch: 5 [24320/50000] Loss: 0.672 | Acc: 76.624%\n",
            "Train Epoch: 5 [25600/50000] Loss: 0.672 | Acc: 76.648%\n",
            "Train Epoch: 5 [26880/50000] Loss: 0.673 | Acc: 76.629%\n",
            "Train Epoch: 5 [28160/50000] Loss: 0.674 | Acc: 76.633%\n",
            "Train Epoch: 5 [29440/50000] Loss: 0.674 | Acc: 76.630%\n",
            "Train Epoch: 5 [30720/50000] Loss: 0.674 | Acc: 76.618%\n",
            "Train Epoch: 5 [32000/50000] Loss: 0.672 | Acc: 76.656%\n",
            "Train Epoch: 5 [33280/50000] Loss: 0.672 | Acc: 76.664%\n",
            "Train Epoch: 5 [34560/50000] Loss: 0.672 | Acc: 76.626%\n",
            "Train Epoch: 5 [35840/50000] Loss: 0.671 | Acc: 76.629%\n",
            "Train Epoch: 5 [37120/50000] Loss: 0.671 | Acc: 76.632%\n",
            "Train Epoch: 5 [38400/50000] Loss: 0.669 | Acc: 76.697%\n",
            "Train Epoch: 5 [39680/50000] Loss: 0.669 | Acc: 76.741%\n",
            "Train Epoch: 5 [40960/50000] Loss: 0.671 | Acc: 76.726%\n",
            "Train Epoch: 5 [42240/50000] Loss: 0.670 | Acc: 76.723%\n",
            "Train Epoch: 5 [43520/50000] Loss: 0.670 | Acc: 76.707%\n",
            "Train Epoch: 5 [44800/50000] Loss: 0.671 | Acc: 76.656%\n",
            "Train Epoch: 5 [46080/50000] Loss: 0.672 | Acc: 76.621%\n",
            "Train Epoch: 5 [47360/50000] Loss: 0.672 | Acc: 76.594%\n",
            "Train Epoch: 5 [48640/50000] Loss: 0.671 | Acc: 76.604%\n",
            "Train Epoch: 5 [31200/50000] Loss: 0.671 | Acc: 76.650%\n",
            "Test Epoch: 5 | Loss: 0.837 | Acc: 71.160%\n",
            "Train Epoch: 6 [0/50000] Loss: 0.723 | Acc: 75.000%\n",
            "Train Epoch: 6 [1280/50000] Loss: 0.640 | Acc: 77.486%\n",
            "Train Epoch: 6 [2560/50000] Loss: 0.636 | Acc: 77.976%\n",
            "Train Epoch: 6 [3840/50000] Loss: 0.628 | Acc: 77.898%\n",
            "Train Epoch: 6 [5120/50000] Loss: 0.620 | Acc: 78.049%\n",
            "Train Epoch: 6 [6400/50000] Loss: 0.626 | Acc: 77.681%\n",
            "Train Epoch: 6 [7680/50000] Loss: 0.637 | Acc: 77.600%\n",
            "Train Epoch: 6 [8960/50000] Loss: 0.644 | Acc: 77.410%\n",
            "Train Epoch: 6 [10240/50000] Loss: 0.645 | Acc: 77.440%\n",
            "Train Epoch: 6 [11520/50000] Loss: 0.641 | Acc: 77.507%\n",
            "Train Epoch: 6 [12800/50000] Loss: 0.646 | Acc: 77.351%\n",
            "Train Epoch: 6 [14080/50000] Loss: 0.646 | Acc: 77.189%\n",
            "Train Epoch: 6 [15360/50000] Loss: 0.649 | Acc: 77.066%\n",
            "Train Epoch: 6 [16640/50000] Loss: 0.651 | Acc: 76.956%\n",
            "Train Epoch: 6 [17920/50000] Loss: 0.653 | Acc: 76.889%\n",
            "Train Epoch: 6 [19200/50000] Loss: 0.653 | Acc: 76.878%\n",
            "Train Epoch: 6 [20480/50000] Loss: 0.648 | Acc: 77.048%\n",
            "Train Epoch: 6 [21760/50000] Loss: 0.648 | Acc: 77.111%\n",
            "Train Epoch: 6 [23040/50000] Loss: 0.647 | Acc: 77.102%\n",
            "Train Epoch: 6 [24320/50000] Loss: 0.651 | Acc: 77.004%\n",
            "Train Epoch: 6 [25600/50000] Loss: 0.648 | Acc: 77.149%\n",
            "Train Epoch: 6 [26880/50000] Loss: 0.644 | Acc: 77.325%\n",
            "Train Epoch: 6 [28160/50000] Loss: 0.643 | Acc: 77.368%\n",
            "Train Epoch: 6 [29440/50000] Loss: 0.642 | Acc: 77.367%\n",
            "Train Epoch: 6 [30720/50000] Loss: 0.643 | Acc: 77.315%\n",
            "Train Epoch: 6 [32000/50000] Loss: 0.642 | Acc: 77.316%\n",
            "Train Epoch: 6 [33280/50000] Loss: 0.642 | Acc: 77.296%\n",
            "Train Epoch: 6 [34560/50000] Loss: 0.641 | Acc: 77.332%\n",
            "Train Epoch: 6 [35840/50000] Loss: 0.639 | Acc: 77.419%\n",
            "Train Epoch: 6 [37120/50000] Loss: 0.639 | Acc: 77.438%\n",
            "Train Epoch: 6 [38400/50000] Loss: 0.639 | Acc: 77.458%\n",
            "Train Epoch: 6 [39680/50000] Loss: 0.640 | Acc: 77.467%\n",
            "Train Epoch: 6 [40960/50000] Loss: 0.641 | Acc: 77.497%\n",
            "Train Epoch: 6 [42240/50000] Loss: 0.642 | Acc: 77.518%\n",
            "Train Epoch: 6 [43520/50000] Loss: 0.641 | Acc: 77.605%\n",
            "Train Epoch: 6 [44800/50000] Loss: 0.641 | Acc: 77.584%\n",
            "Train Epoch: 6 [46080/50000] Loss: 0.640 | Acc: 77.627%\n",
            "Train Epoch: 6 [47360/50000] Loss: 0.639 | Acc: 77.662%\n",
            "Train Epoch: 6 [48640/50000] Loss: 0.639 | Acc: 77.719%\n",
            "Train Epoch: 6 [31200/50000] Loss: 0.638 | Acc: 77.748%\n",
            "Test Epoch: 6 | Loss: 0.862 | Acc: 71.370%\n",
            "Train Epoch: 7 [0/50000] Loss: 0.505 | Acc: 82.812%\n",
            "Train Epoch: 7 [1280/50000] Loss: 0.595 | Acc: 80.185%\n",
            "Train Epoch: 7 [2560/50000] Loss: 0.581 | Acc: 80.022%\n",
            "Train Epoch: 7 [3840/50000] Loss: 0.595 | Acc: 79.713%\n",
            "Train Epoch: 7 [5120/50000] Loss: 0.610 | Acc: 79.306%\n",
            "Train Epoch: 7 [6400/50000] Loss: 0.609 | Acc: 79.350%\n",
            "Train Epoch: 7 [7680/50000] Loss: 0.607 | Acc: 79.585%\n",
            "Train Epoch: 7 [8960/50000] Loss: 0.612 | Acc: 79.412%\n",
            "Train Epoch: 7 [10240/50000] Loss: 0.614 | Acc: 79.273%\n",
            "Train Epoch: 7 [11520/50000] Loss: 0.614 | Acc: 79.310%\n",
            "Train Epoch: 7 [12800/50000] Loss: 0.620 | Acc: 79.061%\n",
            "Train Epoch: 7 [14080/50000] Loss: 0.618 | Acc: 79.068%\n",
            "Train Epoch: 7 [15360/50000] Loss: 0.616 | Acc: 79.119%\n",
            "Train Epoch: 7 [16640/50000] Loss: 0.616 | Acc: 79.061%\n",
            "Train Epoch: 7 [17920/50000] Loss: 0.618 | Acc: 79.056%\n",
            "Train Epoch: 7 [19200/50000] Loss: 0.619 | Acc: 79.010%\n",
            "Train Epoch: 7 [20480/50000] Loss: 0.622 | Acc: 78.916%\n",
            "Train Epoch: 7 [21760/50000] Loss: 0.622 | Acc: 78.824%\n",
            "Train Epoch: 7 [23040/50000] Loss: 0.621 | Acc: 78.833%\n",
            "Train Epoch: 7 [24320/50000] Loss: 0.622 | Acc: 78.784%\n",
            "Train Epoch: 7 [25600/50000] Loss: 0.624 | Acc: 78.724%\n",
            "Train Epoch: 7 [26880/50000] Loss: 0.624 | Acc: 78.762%\n",
            "Train Epoch: 7 [28160/50000] Loss: 0.624 | Acc: 78.691%\n",
            "Train Epoch: 7 [29440/50000] Loss: 0.623 | Acc: 78.703%\n",
            "Train Epoch: 7 [30720/50000] Loss: 0.622 | Acc: 78.747%\n",
            "Train Epoch: 7 [32000/50000] Loss: 0.619 | Acc: 78.832%\n",
            "Train Epoch: 7 [33280/50000] Loss: 0.620 | Acc: 78.861%\n",
            "Train Epoch: 7 [34560/50000] Loss: 0.620 | Acc: 78.935%\n",
            "Train Epoch: 7 [35840/50000] Loss: 0.619 | Acc: 78.970%\n",
            "Train Epoch: 7 [37120/50000] Loss: 0.619 | Acc: 78.917%\n",
            "Train Epoch: 7 [38400/50000] Loss: 0.617 | Acc: 78.961%\n",
            "Train Epoch: 7 [39680/50000] Loss: 0.617 | Acc: 78.946%\n",
            "Train Epoch: 7 [40960/50000] Loss: 0.615 | Acc: 79.004%\n",
            "Train Epoch: 7 [42240/50000] Loss: 0.614 | Acc: 79.038%\n",
            "Train Epoch: 7 [43520/50000] Loss: 0.614 | Acc: 79.055%\n",
            "Train Epoch: 7 [44800/50000] Loss: 0.614 | Acc: 79.091%\n",
            "Train Epoch: 7 [46080/50000] Loss: 0.614 | Acc: 79.077%\n",
            "Train Epoch: 7 [47360/50000] Loss: 0.614 | Acc: 79.047%\n",
            "Train Epoch: 7 [48640/50000] Loss: 0.613 | Acc: 79.021%\n",
            "Train Epoch: 7 [31200/50000] Loss: 0.613 | Acc: 79.046%\n",
            "Test Epoch: 7 | Loss: 0.709 | Acc: 76.020%\n",
            "Train Epoch: 8 [0/50000] Loss: 0.571 | Acc: 79.688%\n",
            "Train Epoch: 8 [1280/50000] Loss: 0.550 | Acc: 81.747%\n",
            "Train Epoch: 8 [2560/50000] Loss: 0.588 | Acc: 79.911%\n",
            "Train Epoch: 8 [3840/50000] Loss: 0.585 | Acc: 79.738%\n",
            "Train Epoch: 8 [5120/50000] Loss: 0.577 | Acc: 79.802%\n",
            "Train Epoch: 8 [6400/50000] Loss: 0.576 | Acc: 79.718%\n",
            "Train Epoch: 8 [7680/50000] Loss: 0.578 | Acc: 79.636%\n",
            "Train Epoch: 8 [8960/50000] Loss: 0.578 | Acc: 79.588%\n",
            "Train Epoch: 8 [10240/50000] Loss: 0.587 | Acc: 79.398%\n",
            "Train Epoch: 8 [11520/50000] Loss: 0.591 | Acc: 79.361%\n",
            "Train Epoch: 8 [12800/50000] Loss: 0.596 | Acc: 79.239%\n",
            "Train Epoch: 8 [14080/50000] Loss: 0.597 | Acc: 79.258%\n",
            "Train Epoch: 8 [15360/50000] Loss: 0.597 | Acc: 79.384%\n",
            "Train Epoch: 8 [16640/50000] Loss: 0.595 | Acc: 79.425%\n",
            "Train Epoch: 8 [17920/50000] Loss: 0.594 | Acc: 79.494%\n",
            "Train Epoch: 8 [19200/50000] Loss: 0.594 | Acc: 79.455%\n",
            "Train Epoch: 8 [20480/50000] Loss: 0.594 | Acc: 79.435%\n",
            "Train Epoch: 8 [21760/50000] Loss: 0.593 | Acc: 79.518%\n",
            "Train Epoch: 8 [23040/50000] Loss: 0.592 | Acc: 79.498%\n",
            "Train Epoch: 8 [24320/50000] Loss: 0.592 | Acc: 79.532%\n",
            "Train Epoch: 8 [25600/50000] Loss: 0.594 | Acc: 79.439%\n",
            "Train Epoch: 8 [26880/50000] Loss: 0.595 | Acc: 79.351%\n",
            "Train Epoch: 8 [28160/50000] Loss: 0.593 | Acc: 79.345%\n",
            "Train Epoch: 8 [29440/50000] Loss: 0.592 | Acc: 79.417%\n",
            "Train Epoch: 8 [30720/50000] Loss: 0.592 | Acc: 79.438%\n",
            "Train Epoch: 8 [32000/50000] Loss: 0.591 | Acc: 79.501%\n",
            "Train Epoch: 8 [33280/50000] Loss: 0.591 | Acc: 79.469%\n",
            "Train Epoch: 8 [34560/50000] Loss: 0.592 | Acc: 79.468%\n",
            "Train Epoch: 8 [35840/50000] Loss: 0.592 | Acc: 79.437%\n",
            "Train Epoch: 8 [37120/50000] Loss: 0.592 | Acc: 79.449%\n",
            "Train Epoch: 8 [38400/50000] Loss: 0.590 | Acc: 79.501%\n",
            "Train Epoch: 8 [39680/50000] Loss: 0.592 | Acc: 79.439%\n",
            "Train Epoch: 8 [40960/50000] Loss: 0.593 | Acc: 79.444%\n",
            "Train Epoch: 8 [42240/50000] Loss: 0.593 | Acc: 79.430%\n",
            "Train Epoch: 8 [43520/50000] Loss: 0.593 | Acc: 79.447%\n",
            "Train Epoch: 8 [44800/50000] Loss: 0.592 | Acc: 79.467%\n",
            "Train Epoch: 8 [46080/50000] Loss: 0.592 | Acc: 79.467%\n",
            "Train Epoch: 8 [47360/50000] Loss: 0.591 | Acc: 79.538%\n",
            "Train Epoch: 8 [48640/50000] Loss: 0.592 | Acc: 79.544%\n",
            "Train Epoch: 8 [31200/50000] Loss: 0.592 | Acc: 79.530%\n",
            "Test Epoch: 8 | Loss: 0.654 | Acc: 77.800%\n",
            "Train Epoch: 9 [0/50000] Loss: 0.507 | Acc: 83.594%\n",
            "Train Epoch: 9 [1280/50000] Loss: 0.597 | Acc: 80.327%\n",
            "Train Epoch: 9 [2560/50000] Loss: 0.595 | Acc: 80.283%\n",
            "Train Epoch: 9 [3840/50000] Loss: 0.597 | Acc: 80.368%\n",
            "Train Epoch: 9 [5120/50000] Loss: 0.588 | Acc: 80.354%\n",
            "Train Epoch: 9 [6400/50000] Loss: 0.575 | Acc: 80.683%\n",
            "Train Epoch: 9 [7680/50000] Loss: 0.579 | Acc: 80.353%\n",
            "Train Epoch: 9 [8960/50000] Loss: 0.581 | Acc: 80.436%\n",
            "Train Epoch: 9 [10240/50000] Loss: 0.580 | Acc: 80.199%\n",
            "Train Epoch: 9 [11520/50000] Loss: 0.583 | Acc: 80.082%\n",
            "Train Epoch: 9 [12800/50000] Loss: 0.582 | Acc: 80.105%\n",
            "Train Epoch: 9 [14080/50000] Loss: 0.579 | Acc: 80.222%\n",
            "Train Epoch: 9 [15360/50000] Loss: 0.577 | Acc: 80.294%\n",
            "Train Epoch: 9 [16640/50000] Loss: 0.580 | Acc: 80.135%\n",
            "Train Epoch: 9 [17920/50000] Loss: 0.580 | Acc: 80.186%\n",
            "Train Epoch: 9 [19200/50000] Loss: 0.580 | Acc: 80.210%\n",
            "Train Epoch: 9 [20480/50000] Loss: 0.583 | Acc: 80.061%\n",
            "Train Epoch: 9 [21760/50000] Loss: 0.582 | Acc: 80.058%\n",
            "Train Epoch: 9 [23040/50000] Loss: 0.581 | Acc: 80.063%\n",
            "Train Epoch: 9 [24320/50000] Loss: 0.581 | Acc: 80.023%\n",
            "Train Epoch: 9 [25600/50000] Loss: 0.580 | Acc: 79.998%\n",
            "Train Epoch: 9 [26880/50000] Loss: 0.579 | Acc: 80.065%\n",
            "Train Epoch: 9 [28160/50000] Loss: 0.581 | Acc: 80.080%\n",
            "Train Epoch: 9 [29440/50000] Loss: 0.580 | Acc: 80.124%\n",
            "Train Epoch: 9 [30720/50000] Loss: 0.579 | Acc: 80.177%\n",
            "Train Epoch: 9 [32000/50000] Loss: 0.578 | Acc: 80.220%\n",
            "Train Epoch: 9 [33280/50000] Loss: 0.580 | Acc: 80.178%\n",
            "Train Epoch: 9 [34560/50000] Loss: 0.579 | Acc: 80.198%\n",
            "Train Epoch: 9 [35840/50000] Loss: 0.579 | Acc: 80.188%\n",
            "Train Epoch: 9 [37120/50000] Loss: 0.579 | Acc: 80.155%\n",
            "Train Epoch: 9 [38400/50000] Loss: 0.579 | Acc: 80.162%\n",
            "Train Epoch: 9 [39680/50000] Loss: 0.579 | Acc: 80.170%\n",
            "Train Epoch: 9 [40960/50000] Loss: 0.578 | Acc: 80.172%\n",
            "Train Epoch: 9 [42240/50000] Loss: 0.579 | Acc: 80.141%\n",
            "Train Epoch: 9 [43520/50000] Loss: 0.581 | Acc: 80.091%\n",
            "Train Epoch: 9 [44800/50000] Loss: 0.581 | Acc: 80.137%\n",
            "Train Epoch: 9 [46080/50000] Loss: 0.583 | Acc: 80.092%\n",
            "Train Epoch: 9 [47360/50000] Loss: 0.583 | Acc: 80.058%\n",
            "Train Epoch: 9 [48640/50000] Loss: 0.581 | Acc: 80.106%\n",
            "Train Epoch: 9 [31200/50000] Loss: 0.582 | Acc: 80.100%\n",
            "Test Epoch: 9 | Loss: 0.687 | Acc: 75.940%\n",
            "Train Epoch: 10 [0/50000] Loss: 0.654 | Acc: 76.562%\n",
            "Train Epoch: 10 [1280/50000] Loss: 0.549 | Acc: 81.250%\n",
            "Train Epoch: 10 [2560/50000] Loss: 0.562 | Acc: 80.915%\n",
            "Train Epoch: 10 [3840/50000] Loss: 0.568 | Acc: 80.217%\n",
            "Train Epoch: 10 [5120/50000] Loss: 0.564 | Acc: 80.621%\n",
            "Train Epoch: 10 [6400/50000] Loss: 0.567 | Acc: 80.392%\n",
            "Train Epoch: 10 [7680/50000] Loss: 0.569 | Acc: 80.430%\n",
            "Train Epoch: 10 [8960/50000] Loss: 0.572 | Acc: 80.194%\n",
            "Train Epoch: 10 [10240/50000] Loss: 0.573 | Acc: 80.179%\n",
            "Train Epoch: 10 [11520/50000] Loss: 0.571 | Acc: 80.237%\n",
            "Train Epoch: 10 [12800/50000] Loss: 0.571 | Acc: 80.237%\n",
            "Train Epoch: 10 [14080/50000] Loss: 0.575 | Acc: 80.068%\n",
            "Train Epoch: 10 [15360/50000] Loss: 0.572 | Acc: 80.172%\n",
            "Train Epoch: 10 [16640/50000] Loss: 0.572 | Acc: 80.165%\n",
            "Train Epoch: 10 [17920/50000] Loss: 0.571 | Acc: 80.258%\n",
            "Train Epoch: 10 [19200/50000] Loss: 0.571 | Acc: 80.257%\n",
            "Train Epoch: 10 [20480/50000] Loss: 0.570 | Acc: 80.294%\n",
            "Train Epoch: 10 [21760/50000] Loss: 0.569 | Acc: 80.350%\n",
            "Train Epoch: 10 [23040/50000] Loss: 0.568 | Acc: 80.413%\n",
            "Train Epoch: 10 [24320/50000] Loss: 0.569 | Acc: 80.346%\n",
            "Train Epoch: 10 [25600/50000] Loss: 0.571 | Acc: 80.344%\n",
            "Train Epoch: 10 [26880/50000] Loss: 0.573 | Acc: 80.254%\n",
            "Train Epoch: 10 [28160/50000] Loss: 0.573 | Acc: 80.221%\n",
            "Train Epoch: 10 [29440/50000] Loss: 0.573 | Acc: 80.208%\n",
            "Train Epoch: 10 [30720/50000] Loss: 0.573 | Acc: 80.219%\n",
            "Train Epoch: 10 [32000/50000] Loss: 0.572 | Acc: 80.245%\n",
            "Train Epoch: 10 [33280/50000] Loss: 0.571 | Acc: 80.280%\n",
            "Train Epoch: 10 [34560/50000] Loss: 0.570 | Acc: 80.336%\n",
            "Train Epoch: 10 [35840/50000] Loss: 0.570 | Acc: 80.338%\n",
            "Train Epoch: 10 [37120/50000] Loss: 0.571 | Acc: 80.289%\n",
            "Train Epoch: 10 [38400/50000] Loss: 0.572 | Acc: 80.274%\n",
            "Train Epoch: 10 [39680/50000] Loss: 0.572 | Acc: 80.310%\n",
            "Train Epoch: 10 [40960/50000] Loss: 0.572 | Acc: 80.257%\n",
            "Train Epoch: 10 [42240/50000] Loss: 0.571 | Acc: 80.282%\n",
            "Train Epoch: 10 [43520/50000] Loss: 0.571 | Acc: 80.265%\n",
            "Train Epoch: 10 [44800/50000] Loss: 0.572 | Acc: 80.219%\n",
            "Train Epoch: 10 [46080/50000] Loss: 0.571 | Acc: 80.237%\n",
            "Train Epoch: 10 [47360/50000] Loss: 0.572 | Acc: 80.222%\n",
            "Train Epoch: 10 [48640/50000] Loss: 0.574 | Acc: 80.173%\n",
            "Train Epoch: 10 [31200/50000] Loss: 0.573 | Acc: 80.176%\n",
            "Test Epoch: 10 | Loss: 0.729 | Acc: 76.430%\n",
            "Train Epoch: 11 [0/50000] Loss: 0.500 | Acc: 82.031%\n",
            "Train Epoch: 11 [1280/50000] Loss: 0.556 | Acc: 80.611%\n",
            "Train Epoch: 11 [2560/50000] Loss: 0.562 | Acc: 80.283%\n",
            "Train Epoch: 11 [3840/50000] Loss: 0.541 | Acc: 81.225%\n",
            "Train Epoch: 11 [5120/50000] Loss: 0.552 | Acc: 80.526%\n",
            "Train Epoch: 11 [6400/50000] Loss: 0.553 | Acc: 80.499%\n",
            "Train Epoch: 11 [7680/50000] Loss: 0.553 | Acc: 80.571%\n",
            "Train Epoch: 11 [8960/50000] Loss: 0.557 | Acc: 80.568%\n",
            "Train Epoch: 11 [10240/50000] Loss: 0.555 | Acc: 80.720%\n",
            "Train Epoch: 11 [11520/50000] Loss: 0.558 | Acc: 80.683%\n",
            "Train Epoch: 11 [12800/50000] Loss: 0.561 | Acc: 80.531%\n",
            "Train Epoch: 11 [14080/50000] Loss: 0.561 | Acc: 80.546%\n",
            "Train Epoch: 11 [15360/50000] Loss: 0.566 | Acc: 80.340%\n",
            "Train Epoch: 11 [16640/50000] Loss: 0.572 | Acc: 80.069%\n",
            "Train Epoch: 11 [17920/50000] Loss: 0.574 | Acc: 79.965%\n",
            "Train Epoch: 11 [19200/50000] Loss: 0.573 | Acc: 80.076%\n",
            "Train Epoch: 11 [20480/50000] Loss: 0.571 | Acc: 80.236%\n",
            "Train Epoch: 11 [21760/50000] Loss: 0.569 | Acc: 80.249%\n",
            "Train Epoch: 11 [23040/50000] Loss: 0.567 | Acc: 80.292%\n",
            "Train Epoch: 11 [24320/50000] Loss: 0.566 | Acc: 80.326%\n",
            "Train Epoch: 11 [25600/50000] Loss: 0.566 | Acc: 80.286%\n",
            "Train Epoch: 11 [26880/50000] Loss: 0.567 | Acc: 80.206%\n",
            "Train Epoch: 11 [28160/50000] Loss: 0.568 | Acc: 80.168%\n",
            "Train Epoch: 11 [29440/50000] Loss: 0.568 | Acc: 80.144%\n",
            "Train Epoch: 11 [30720/50000] Loss: 0.570 | Acc: 80.077%\n",
            "Train Epoch: 11 [32000/50000] Loss: 0.570 | Acc: 80.067%\n",
            "Train Epoch: 11 [33280/50000] Loss: 0.568 | Acc: 80.110%\n",
            "Train Epoch: 11 [34560/50000] Loss: 0.567 | Acc: 80.175%\n",
            "Train Epoch: 11 [35840/50000] Loss: 0.566 | Acc: 80.219%\n",
            "Train Epoch: 11 [37120/50000] Loss: 0.566 | Acc: 80.224%\n",
            "Train Epoch: 11 [38400/50000] Loss: 0.565 | Acc: 80.233%\n",
            "Train Epoch: 11 [39680/50000] Loss: 0.566 | Acc: 80.205%\n",
            "Train Epoch: 11 [40960/50000] Loss: 0.567 | Acc: 80.177%\n",
            "Train Epoch: 11 [42240/50000] Loss: 0.565 | Acc: 80.226%\n",
            "Train Epoch: 11 [43520/50000] Loss: 0.564 | Acc: 80.285%\n",
            "Train Epoch: 11 [44800/50000] Loss: 0.564 | Acc: 80.295%\n",
            "Train Epoch: 11 [46080/50000] Loss: 0.565 | Acc: 80.272%\n",
            "Train Epoch: 11 [47360/50000] Loss: 0.565 | Acc: 80.271%\n",
            "Train Epoch: 11 [48640/50000] Loss: 0.563 | Acc: 80.331%\n",
            "Train Epoch: 11 [31200/50000] Loss: 0.565 | Acc: 80.270%\n",
            "Test Epoch: 11 | Loss: 0.601 | Acc: 79.740%\n",
            "Train Epoch: 12 [0/50000] Loss: 0.468 | Acc: 83.594%\n",
            "Train Epoch: 12 [1280/50000] Loss: 0.504 | Acc: 83.168%\n",
            "Train Epoch: 12 [2560/50000] Loss: 0.519 | Acc: 82.329%\n",
            "Train Epoch: 12 [3840/50000] Loss: 0.529 | Acc: 82.031%\n",
            "Train Epoch: 12 [5120/50000] Loss: 0.543 | Acc: 81.364%\n",
            "Train Epoch: 12 [6400/50000] Loss: 0.539 | Acc: 81.480%\n",
            "Train Epoch: 12 [7680/50000] Loss: 0.533 | Acc: 81.660%\n",
            "Train Epoch: 12 [8960/50000] Loss: 0.533 | Acc: 81.789%\n",
            "Train Epoch: 12 [10240/50000] Loss: 0.537 | Acc: 81.626%\n",
            "Train Epoch: 12 [11520/50000] Loss: 0.538 | Acc: 81.559%\n",
            "Train Epoch: 12 [12800/50000] Loss: 0.541 | Acc: 81.436%\n",
            "Train Epoch: 12 [14080/50000] Loss: 0.542 | Acc: 81.468%\n",
            "Train Epoch: 12 [15360/50000] Loss: 0.546 | Acc: 81.282%\n",
            "Train Epoch: 12 [16640/50000] Loss: 0.548 | Acc: 81.137%\n",
            "Train Epoch: 12 [17920/50000] Loss: 0.551 | Acc: 81.006%\n",
            "Train Epoch: 12 [19200/50000] Loss: 0.553 | Acc: 80.965%\n",
            "Train Epoch: 12 [20480/50000] Loss: 0.549 | Acc: 81.022%\n",
            "Train Epoch: 12 [21760/50000] Loss: 0.546 | Acc: 81.149%\n",
            "Train Epoch: 12 [23040/50000] Loss: 0.546 | Acc: 81.142%\n",
            "Train Epoch: 12 [24320/50000] Loss: 0.546 | Acc: 81.172%\n",
            "Train Epoch: 12 [25600/50000] Loss: 0.547 | Acc: 81.153%\n",
            "Train Epoch: 12 [26880/50000] Loss: 0.548 | Acc: 81.124%\n",
            "Train Epoch: 12 [28160/50000] Loss: 0.550 | Acc: 81.094%\n",
            "Train Epoch: 12 [29440/50000] Loss: 0.551 | Acc: 81.094%\n",
            "Train Epoch: 12 [30720/50000] Loss: 0.550 | Acc: 81.091%\n",
            "Train Epoch: 12 [32000/50000] Loss: 0.552 | Acc: 81.051%\n",
            "Train Epoch: 12 [33280/50000] Loss: 0.551 | Acc: 81.064%\n",
            "Train Epoch: 12 [34560/50000] Loss: 0.550 | Acc: 81.109%\n",
            "Train Epoch: 12 [35840/50000] Loss: 0.551 | Acc: 81.064%\n",
            "Train Epoch: 12 [37120/50000] Loss: 0.553 | Acc: 81.019%\n",
            "Train Epoch: 12 [38400/50000] Loss: 0.551 | Acc: 81.055%\n",
            "Train Epoch: 12 [39680/50000] Loss: 0.552 | Acc: 81.052%\n",
            "Train Epoch: 12 [40960/50000] Loss: 0.551 | Acc: 81.046%\n",
            "Train Epoch: 12 [42240/50000] Loss: 0.551 | Acc: 81.040%\n",
            "Train Epoch: 12 [43520/50000] Loss: 0.551 | Acc: 81.076%\n",
            "Train Epoch: 12 [44800/50000] Loss: 0.551 | Acc: 81.050%\n",
            "Train Epoch: 12 [46080/50000] Loss: 0.553 | Acc: 80.984%\n",
            "Train Epoch: 12 [47360/50000] Loss: 0.553 | Acc: 80.989%\n",
            "Train Epoch: 12 [48640/50000] Loss: 0.553 | Acc: 80.981%\n",
            "Train Epoch: 12 [31200/50000] Loss: 0.553 | Acc: 81.034%\n",
            "Test Epoch: 12 | Loss: 0.723 | Acc: 75.030%\n",
            "Train Epoch: 13 [0/50000] Loss: 0.482 | Acc: 85.938%\n",
            "Train Epoch: 13 [1280/50000] Loss: 0.595 | Acc: 79.616%\n",
            "Train Epoch: 13 [2560/50000] Loss: 0.560 | Acc: 81.213%\n",
            "Train Epoch: 13 [3840/50000] Loss: 0.549 | Acc: 81.804%\n",
            "Train Epoch: 13 [5120/50000] Loss: 0.549 | Acc: 81.593%\n",
            "Train Epoch: 13 [6400/50000] Loss: 0.555 | Acc: 81.327%\n",
            "Train Epoch: 13 [7680/50000] Loss: 0.548 | Acc: 81.429%\n",
            "Train Epoch: 13 [8960/50000] Loss: 0.552 | Acc: 81.371%\n",
            "Train Epoch: 13 [10240/50000] Loss: 0.551 | Acc: 81.211%\n",
            "Train Epoch: 13 [11520/50000] Loss: 0.550 | Acc: 81.259%\n",
            "Train Epoch: 13 [12800/50000] Loss: 0.545 | Acc: 81.374%\n",
            "Train Epoch: 13 [14080/50000] Loss: 0.543 | Acc: 81.454%\n",
            "Train Epoch: 13 [15360/50000] Loss: 0.541 | Acc: 81.502%\n",
            "Train Epoch: 13 [16640/50000] Loss: 0.541 | Acc: 81.417%\n",
            "Train Epoch: 13 [17920/50000] Loss: 0.541 | Acc: 81.466%\n",
            "Train Epoch: 13 [19200/50000] Loss: 0.539 | Acc: 81.504%\n",
            "Train Epoch: 13 [20480/50000] Loss: 0.542 | Acc: 81.415%\n",
            "Train Epoch: 13 [21760/50000] Loss: 0.545 | Acc: 81.309%\n",
            "Train Epoch: 13 [23040/50000] Loss: 0.546 | Acc: 81.254%\n",
            "Train Epoch: 13 [24320/50000] Loss: 0.544 | Acc: 81.320%\n",
            "Train Epoch: 13 [25600/50000] Loss: 0.541 | Acc: 81.394%\n",
            "Train Epoch: 13 [26880/50000] Loss: 0.540 | Acc: 81.487%\n",
            "Train Epoch: 13 [28160/50000] Loss: 0.541 | Acc: 81.434%\n",
            "Train Epoch: 13 [29440/50000] Loss: 0.540 | Acc: 81.477%\n",
            "Train Epoch: 13 [30720/50000] Loss: 0.540 | Acc: 81.477%\n",
            "Train Epoch: 13 [32000/50000] Loss: 0.542 | Acc: 81.431%\n",
            "Train Epoch: 13 [33280/50000] Loss: 0.540 | Acc: 81.463%\n",
            "Train Epoch: 13 [34560/50000] Loss: 0.540 | Acc: 81.446%\n",
            "Train Epoch: 13 [35840/50000] Loss: 0.539 | Acc: 81.536%\n",
            "Train Epoch: 13 [37120/50000] Loss: 0.539 | Acc: 81.543%\n",
            "Train Epoch: 13 [38400/50000] Loss: 0.539 | Acc: 81.580%\n",
            "Train Epoch: 13 [39680/50000] Loss: 0.540 | Acc: 81.546%\n",
            "Train Epoch: 13 [40960/50000] Loss: 0.538 | Acc: 81.593%\n",
            "Train Epoch: 13 [42240/50000] Loss: 0.538 | Acc: 81.604%\n",
            "Train Epoch: 13 [43520/50000] Loss: 0.538 | Acc: 81.619%\n",
            "Train Epoch: 13 [44800/50000] Loss: 0.538 | Acc: 81.611%\n",
            "Train Epoch: 13 [46080/50000] Loss: 0.539 | Acc: 81.572%\n",
            "Train Epoch: 13 [47360/50000] Loss: 0.539 | Acc: 81.566%\n",
            "Train Epoch: 13 [48640/50000] Loss: 0.540 | Acc: 81.533%\n",
            "Train Epoch: 13 [31200/50000] Loss: 0.541 | Acc: 81.490%\n",
            "Test Epoch: 13 | Loss: 1.056 | Acc: 67.540%\n",
            "Train Epoch: 14 [0/50000] Loss: 0.489 | Acc: 81.250%\n",
            "Train Epoch: 14 [1280/50000] Loss: 0.511 | Acc: 82.884%\n",
            "Train Epoch: 14 [2560/50000] Loss: 0.517 | Acc: 82.999%\n",
            "Train Epoch: 14 [3840/50000] Loss: 0.531 | Acc: 82.762%\n",
            "Train Epoch: 14 [5120/50000] Loss: 0.539 | Acc: 82.393%\n",
            "Train Epoch: 14 [6400/50000] Loss: 0.539 | Acc: 82.123%\n",
            "Train Epoch: 14 [7680/50000] Loss: 0.540 | Acc: 81.942%\n",
            "Train Epoch: 14 [8960/50000] Loss: 0.538 | Acc: 81.910%\n",
            "Train Epoch: 14 [10240/50000] Loss: 0.535 | Acc: 82.012%\n",
            "Train Epoch: 14 [11520/50000] Loss: 0.539 | Acc: 81.842%\n",
            "Train Epoch: 14 [12800/50000] Loss: 0.539 | Acc: 81.884%\n",
            "Train Epoch: 14 [14080/50000] Loss: 0.539 | Acc: 81.820%\n",
            "Train Epoch: 14 [15360/50000] Loss: 0.538 | Acc: 81.805%\n",
            "Train Epoch: 14 [16640/50000] Loss: 0.535 | Acc: 81.828%\n",
            "Train Epoch: 14 [17920/50000] Loss: 0.535 | Acc: 81.815%\n",
            "Train Epoch: 14 [19200/50000] Loss: 0.535 | Acc: 81.679%\n",
            "Train Epoch: 14 [20480/50000] Loss: 0.537 | Acc: 81.614%\n",
            "Train Epoch: 14 [21760/50000] Loss: 0.536 | Acc: 81.593%\n",
            "Train Epoch: 14 [23040/50000] Loss: 0.537 | Acc: 81.505%\n",
            "Train Epoch: 14 [24320/50000] Loss: 0.538 | Acc: 81.479%\n",
            "Train Epoch: 14 [25600/50000] Loss: 0.538 | Acc: 81.448%\n",
            "Train Epoch: 14 [26880/50000] Loss: 0.539 | Acc: 81.387%\n",
            "Train Epoch: 14 [28160/50000] Loss: 0.538 | Acc: 81.391%\n",
            "Train Epoch: 14 [29440/50000] Loss: 0.539 | Acc: 81.399%\n",
            "Train Epoch: 14 [30720/50000] Loss: 0.542 | Acc: 81.256%\n",
            "Train Epoch: 14 [32000/50000] Loss: 0.541 | Acc: 81.281%\n",
            "Train Epoch: 14 [33280/50000] Loss: 0.542 | Acc: 81.259%\n",
            "Train Epoch: 14 [34560/50000] Loss: 0.543 | Acc: 81.221%\n",
            "Train Epoch: 14 [35840/50000] Loss: 0.542 | Acc: 81.236%\n",
            "Train Epoch: 14 [37120/50000] Loss: 0.542 | Acc: 81.261%\n",
            "Train Epoch: 14 [38400/50000] Loss: 0.541 | Acc: 81.333%\n",
            "Train Epoch: 14 [39680/50000] Loss: 0.541 | Acc: 81.356%\n",
            "Train Epoch: 14 [40960/50000] Loss: 0.540 | Acc: 81.357%\n",
            "Train Epoch: 14 [42240/50000] Loss: 0.538 | Acc: 81.420%\n",
            "Train Epoch: 14 [43520/50000] Loss: 0.539 | Acc: 81.397%\n",
            "Train Epoch: 14 [44800/50000] Loss: 0.538 | Acc: 81.417%\n",
            "Train Epoch: 14 [46080/50000] Loss: 0.538 | Acc: 81.397%\n",
            "Train Epoch: 14 [47360/50000] Loss: 0.537 | Acc: 81.433%\n",
            "Train Epoch: 14 [48640/50000] Loss: 0.537 | Acc: 81.453%\n",
            "Train Epoch: 14 [31200/50000] Loss: 0.536 | Acc: 81.494%\n",
            "Test Epoch: 14 | Loss: 0.737 | Acc: 76.360%\n",
            "Train Epoch: 15 [0/50000] Loss: 0.540 | Acc: 83.594%\n",
            "Train Epoch: 15 [1280/50000] Loss: 0.500 | Acc: 82.812%\n",
            "Train Epoch: 15 [2560/50000] Loss: 0.507 | Acc: 81.994%\n",
            "Train Epoch: 15 [3840/50000] Loss: 0.541 | Acc: 81.200%\n",
            "Train Epoch: 15 [5120/50000] Loss: 0.534 | Acc: 81.421%\n",
            "Train Epoch: 15 [6400/50000] Loss: 0.524 | Acc: 81.756%\n",
            "Train Epoch: 15 [7680/50000] Loss: 0.519 | Acc: 81.954%\n",
            "Train Epoch: 15 [8960/50000] Loss: 0.521 | Acc: 81.833%\n",
            "Train Epoch: 15 [10240/50000] Loss: 0.517 | Acc: 82.060%\n",
            "Train Epoch: 15 [11520/50000] Loss: 0.514 | Acc: 82.280%\n",
            "Train Epoch: 15 [12800/50000] Loss: 0.512 | Acc: 82.271%\n",
            "Train Epoch: 15 [14080/50000] Loss: 0.512 | Acc: 82.285%\n",
            "Train Epoch: 15 [15360/50000] Loss: 0.509 | Acc: 82.432%\n",
            "Train Epoch: 15 [16640/50000] Loss: 0.511 | Acc: 82.365%\n",
            "Train Epoch: 15 [17920/50000] Loss: 0.513 | Acc: 82.347%\n",
            "Train Epoch: 15 [19200/50000] Loss: 0.516 | Acc: 82.145%\n",
            "Train Epoch: 15 [20480/50000] Loss: 0.516 | Acc: 82.109%\n",
            "Train Epoch: 15 [21760/50000] Loss: 0.517 | Acc: 82.040%\n",
            "Train Epoch: 15 [23040/50000] Loss: 0.519 | Acc: 81.936%\n",
            "Train Epoch: 15 [24320/50000] Loss: 0.519 | Acc: 81.982%\n",
            "Train Epoch: 15 [25600/50000] Loss: 0.517 | Acc: 82.051%\n",
            "Train Epoch: 15 [26880/50000] Loss: 0.516 | Acc: 82.102%\n",
            "Train Epoch: 15 [28160/50000] Loss: 0.516 | Acc: 82.116%\n",
            "Train Epoch: 15 [29440/50000] Loss: 0.518 | Acc: 82.058%\n",
            "Train Epoch: 15 [30720/50000] Loss: 0.520 | Acc: 82.012%\n",
            "Train Epoch: 15 [32000/50000] Loss: 0.521 | Acc: 81.944%\n",
            "Train Epoch: 15 [33280/50000] Loss: 0.522 | Acc: 81.906%\n",
            "Train Epoch: 15 [34560/50000] Loss: 0.523 | Acc: 81.835%\n",
            "Train Epoch: 15 [35840/50000] Loss: 0.525 | Acc: 81.764%\n",
            "Train Epoch: 15 [37120/50000] Loss: 0.524 | Acc: 81.814%\n",
            "Train Epoch: 15 [38400/50000] Loss: 0.524 | Acc: 81.779%\n",
            "Train Epoch: 15 [39680/50000] Loss: 0.524 | Acc: 81.778%\n",
            "Train Epoch: 15 [40960/50000] Loss: 0.526 | Acc: 81.734%\n",
            "Train Epoch: 15 [42240/50000] Loss: 0.525 | Acc: 81.774%\n",
            "Train Epoch: 15 [43520/50000] Loss: 0.525 | Acc: 81.749%\n",
            "Train Epoch: 15 [44800/50000] Loss: 0.526 | Acc: 81.720%\n",
            "Train Epoch: 15 [46080/50000] Loss: 0.527 | Acc: 81.722%\n",
            "Train Epoch: 15 [47360/50000] Loss: 0.529 | Acc: 81.686%\n",
            "Train Epoch: 15 [48640/50000] Loss: 0.529 | Acc: 81.656%\n",
            "Train Epoch: 15 [31200/50000] Loss: 0.531 | Acc: 81.638%\n",
            "Test Epoch: 15 | Loss: 0.752 | Acc: 74.400%\n",
            "Train Epoch: 16 [0/50000] Loss: 0.680 | Acc: 81.250%\n",
            "Train Epoch: 16 [1280/50000] Loss: 0.519 | Acc: 82.457%\n",
            "Train Epoch: 16 [2560/50000] Loss: 0.519 | Acc: 82.775%\n",
            "Train Epoch: 16 [3840/50000] Loss: 0.519 | Acc: 82.334%\n",
            "Train Epoch: 16 [5120/50000] Loss: 0.512 | Acc: 82.641%\n",
            "Train Epoch: 16 [6400/50000] Loss: 0.514 | Acc: 82.368%\n",
            "Train Epoch: 16 [7680/50000] Loss: 0.523 | Acc: 82.006%\n",
            "Train Epoch: 16 [8960/50000] Loss: 0.523 | Acc: 81.976%\n",
            "Train Epoch: 16 [10240/50000] Loss: 0.524 | Acc: 81.993%\n",
            "Train Epoch: 16 [11520/50000] Loss: 0.525 | Acc: 81.928%\n",
            "Train Epoch: 16 [12800/50000] Loss: 0.526 | Acc: 81.892%\n",
            "Train Epoch: 16 [14080/50000] Loss: 0.524 | Acc: 81.799%\n",
            "Train Epoch: 16 [15360/50000] Loss: 0.527 | Acc: 81.663%\n",
            "Train Epoch: 16 [16640/50000] Loss: 0.530 | Acc: 81.554%\n",
            "Train Epoch: 16 [17920/50000] Loss: 0.526 | Acc: 81.715%\n",
            "Train Epoch: 16 [19200/50000] Loss: 0.525 | Acc: 81.767%\n",
            "Train Epoch: 16 [20480/50000] Loss: 0.523 | Acc: 81.857%\n",
            "Train Epoch: 16 [21760/50000] Loss: 0.522 | Acc: 81.876%\n",
            "Train Epoch: 16 [23040/50000] Loss: 0.524 | Acc: 81.820%\n",
            "Train Epoch: 16 [24320/50000] Loss: 0.526 | Acc: 81.745%\n",
            "Train Epoch: 16 [25600/50000] Loss: 0.525 | Acc: 81.748%\n",
            "Train Epoch: 16 [26880/50000] Loss: 0.526 | Acc: 81.768%\n",
            "Train Epoch: 16 [28160/50000] Loss: 0.527 | Acc: 81.720%\n",
            "Train Epoch: 16 [29440/50000] Loss: 0.528 | Acc: 81.761%\n",
            "Train Epoch: 16 [30720/50000] Loss: 0.528 | Acc: 81.710%\n",
            "Train Epoch: 16 [32000/50000] Loss: 0.528 | Acc: 81.714%\n",
            "Train Epoch: 16 [33280/50000] Loss: 0.530 | Acc: 81.681%\n",
            "Train Epoch: 16 [34560/50000] Loss: 0.531 | Acc: 81.636%\n",
            "Train Epoch: 16 [35840/50000] Loss: 0.532 | Acc: 81.673%\n",
            "Train Epoch: 16 [37120/50000] Loss: 0.532 | Acc: 81.671%\n",
            "Train Epoch: 16 [38400/50000] Loss: 0.534 | Acc: 81.629%\n",
            "Train Epoch: 16 [39680/50000] Loss: 0.533 | Acc: 81.652%\n",
            "Train Epoch: 16 [40960/50000] Loss: 0.532 | Acc: 81.671%\n",
            "Train Epoch: 16 [42240/50000] Loss: 0.533 | Acc: 81.663%\n",
            "Train Epoch: 16 [43520/50000] Loss: 0.532 | Acc: 81.692%\n",
            "Train Epoch: 16 [44800/50000] Loss: 0.531 | Acc: 81.688%\n",
            "Train Epoch: 16 [46080/50000] Loss: 0.531 | Acc: 81.676%\n",
            "Train Epoch: 16 [47360/50000] Loss: 0.531 | Acc: 81.680%\n",
            "Train Epoch: 16 [48640/50000] Loss: 0.530 | Acc: 81.734%\n",
            "Train Epoch: 16 [31200/50000] Loss: 0.530 | Acc: 81.738%\n",
            "Test Epoch: 16 | Loss: 0.612 | Acc: 78.520%\n",
            "Train Epoch: 17 [0/50000] Loss: 0.456 | Acc: 82.812%\n",
            "Train Epoch: 17 [1280/50000] Loss: 0.532 | Acc: 81.321%\n",
            "Train Epoch: 17 [2560/50000] Loss: 0.507 | Acc: 82.589%\n",
            "Train Epoch: 17 [3840/50000] Loss: 0.507 | Acc: 82.258%\n",
            "Train Epoch: 17 [5120/50000] Loss: 0.508 | Acc: 82.279%\n",
            "Train Epoch: 17 [6400/50000] Loss: 0.513 | Acc: 82.077%\n",
            "Train Epoch: 17 [7680/50000] Loss: 0.510 | Acc: 82.364%\n",
            "Train Epoch: 17 [8960/50000] Loss: 0.510 | Acc: 82.361%\n",
            "Train Epoch: 17 [10240/50000] Loss: 0.502 | Acc: 82.591%\n",
            "Train Epoch: 17 [11520/50000] Loss: 0.500 | Acc: 82.701%\n",
            "Train Epoch: 17 [12800/50000] Loss: 0.498 | Acc: 82.820%\n",
            "Train Epoch: 17 [14080/50000] Loss: 0.498 | Acc: 82.897%\n",
            "Train Epoch: 17 [15360/50000] Loss: 0.498 | Acc: 82.851%\n",
            "Train Epoch: 17 [16640/50000] Loss: 0.500 | Acc: 82.771%\n",
            "Train Epoch: 17 [17920/50000] Loss: 0.502 | Acc: 82.740%\n",
            "Train Epoch: 17 [19200/50000] Loss: 0.506 | Acc: 82.683%\n",
            "Train Epoch: 17 [20480/50000] Loss: 0.507 | Acc: 82.643%\n",
            "Train Epoch: 17 [21760/50000] Loss: 0.508 | Acc: 82.598%\n",
            "Train Epoch: 17 [23040/50000] Loss: 0.509 | Acc: 82.614%\n",
            "Train Epoch: 17 [24320/50000] Loss: 0.509 | Acc: 82.616%\n",
            "Train Epoch: 17 [25600/50000] Loss: 0.510 | Acc: 82.587%\n",
            "Train Epoch: 17 [26880/50000] Loss: 0.511 | Acc: 82.553%\n",
            "Train Epoch: 17 [28160/50000] Loss: 0.512 | Acc: 82.494%\n",
            "Train Epoch: 17 [29440/50000] Loss: 0.512 | Acc: 82.505%\n",
            "Train Epoch: 17 [30720/50000] Loss: 0.512 | Acc: 82.521%\n",
            "Train Epoch: 17 [32000/50000] Loss: 0.512 | Acc: 82.501%\n",
            "Train Epoch: 17 [33280/50000] Loss: 0.514 | Acc: 82.423%\n",
            "Train Epoch: 17 [34560/50000] Loss: 0.514 | Acc: 82.458%\n",
            "Train Epoch: 17 [35840/50000] Loss: 0.516 | Acc: 82.412%\n",
            "Train Epoch: 17 [37120/50000] Loss: 0.516 | Acc: 82.396%\n",
            "Train Epoch: 17 [38400/50000] Loss: 0.516 | Acc: 82.384%\n",
            "Train Epoch: 17 [39680/50000] Loss: 0.518 | Acc: 82.320%\n",
            "Train Epoch: 17 [40960/50000] Loss: 0.518 | Acc: 82.333%\n",
            "Train Epoch: 17 [42240/50000] Loss: 0.517 | Acc: 82.364%\n",
            "Train Epoch: 17 [43520/50000] Loss: 0.517 | Acc: 82.345%\n",
            "Train Epoch: 17 [44800/50000] Loss: 0.517 | Acc: 82.347%\n",
            "Train Epoch: 17 [46080/50000] Loss: 0.517 | Acc: 82.339%\n",
            "Train Epoch: 17 [47360/50000] Loss: 0.518 | Acc: 82.334%\n",
            "Train Epoch: 17 [48640/50000] Loss: 0.518 | Acc: 82.308%\n",
            "Train Epoch: 17 [31200/50000] Loss: 0.518 | Acc: 82.328%\n",
            "Test Epoch: 17 | Loss: 0.710 | Acc: 76.500%\n",
            "Train Epoch: 18 [0/50000] Loss: 0.515 | Acc: 85.156%\n",
            "Train Epoch: 18 [1280/50000] Loss: 0.540 | Acc: 81.889%\n",
            "Train Epoch: 18 [2560/50000] Loss: 0.552 | Acc: 81.548%\n",
            "Train Epoch: 18 [3840/50000] Loss: 0.532 | Acc: 82.182%\n",
            "Train Epoch: 18 [5120/50000] Loss: 0.518 | Acc: 82.412%\n",
            "Train Epoch: 18 [6400/50000] Loss: 0.515 | Acc: 82.414%\n",
            "Train Epoch: 18 [7680/50000] Loss: 0.519 | Acc: 82.339%\n",
            "Train Epoch: 18 [8960/50000] Loss: 0.519 | Acc: 82.284%\n",
            "Train Epoch: 18 [10240/50000] Loss: 0.519 | Acc: 82.166%\n",
            "Train Epoch: 18 [11520/50000] Loss: 0.519 | Acc: 82.143%\n",
            "Train Epoch: 18 [12800/50000] Loss: 0.521 | Acc: 82.039%\n",
            "Train Epoch: 18 [14080/50000] Loss: 0.518 | Acc: 82.144%\n",
            "Train Epoch: 18 [15360/50000] Loss: 0.516 | Acc: 82.218%\n",
            "Train Epoch: 18 [16640/50000] Loss: 0.516 | Acc: 82.228%\n",
            "Train Epoch: 18 [17920/50000] Loss: 0.514 | Acc: 82.209%\n",
            "Train Epoch: 18 [19200/50000] Loss: 0.516 | Acc: 82.135%\n",
            "Train Epoch: 18 [20480/50000] Loss: 0.515 | Acc: 82.196%\n",
            "Train Epoch: 18 [21760/50000] Loss: 0.512 | Acc: 82.337%\n",
            "Train Epoch: 18 [23040/50000] Loss: 0.512 | Acc: 82.411%\n",
            "Train Epoch: 18 [24320/50000] Loss: 0.510 | Acc: 82.489%\n",
            "Train Epoch: 18 [25600/50000] Loss: 0.512 | Acc: 82.366%\n",
            "Train Epoch: 18 [26880/50000] Loss: 0.513 | Acc: 82.405%\n",
            "Train Epoch: 18 [28160/50000] Loss: 0.513 | Acc: 82.427%\n",
            "Train Epoch: 18 [29440/50000] Loss: 0.514 | Acc: 82.393%\n",
            "Train Epoch: 18 [30720/50000] Loss: 0.512 | Acc: 82.436%\n",
            "Train Epoch: 18 [32000/50000] Loss: 0.513 | Acc: 82.374%\n",
            "Train Epoch: 18 [33280/50000] Loss: 0.514 | Acc: 82.349%\n",
            "Train Epoch: 18 [34560/50000] Loss: 0.516 | Acc: 82.317%\n",
            "Train Epoch: 18 [35840/50000] Loss: 0.513 | Acc: 82.415%\n",
            "Train Epoch: 18 [37120/50000] Loss: 0.512 | Acc: 82.421%\n",
            "Train Epoch: 18 [38400/50000] Loss: 0.513 | Acc: 82.408%\n",
            "Train Epoch: 18 [39680/50000] Loss: 0.512 | Acc: 82.436%\n",
            "Train Epoch: 18 [40960/50000] Loss: 0.514 | Acc: 82.406%\n",
            "Train Epoch: 18 [42240/50000] Loss: 0.513 | Acc: 82.432%\n",
            "Train Epoch: 18 [43520/50000] Loss: 0.512 | Acc: 82.478%\n",
            "Train Epoch: 18 [44800/50000] Loss: 0.511 | Acc: 82.521%\n",
            "Train Epoch: 18 [46080/50000] Loss: 0.511 | Acc: 82.557%\n",
            "Train Epoch: 18 [47360/50000] Loss: 0.510 | Acc: 82.591%\n",
            "Train Epoch: 18 [48640/50000] Loss: 0.509 | Acc: 82.618%\n",
            "Train Epoch: 18 [31200/50000] Loss: 0.508 | Acc: 82.638%\n",
            "Test Epoch: 18 | Loss: 0.688 | Acc: 77.610%\n",
            "Train Epoch: 19 [0/50000] Loss: 0.506 | Acc: 80.469%\n",
            "Train Epoch: 19 [1280/50000] Loss: 0.515 | Acc: 81.960%\n",
            "Train Epoch: 19 [2560/50000] Loss: 0.506 | Acc: 82.217%\n",
            "Train Epoch: 19 [3840/50000] Loss: 0.514 | Acc: 81.981%\n",
            "Train Epoch: 19 [5120/50000] Loss: 0.508 | Acc: 81.955%\n",
            "Train Epoch: 19 [6400/50000] Loss: 0.512 | Acc: 82.261%\n",
            "Train Epoch: 19 [7680/50000] Loss: 0.508 | Acc: 82.441%\n",
            "Train Epoch: 19 [8960/50000] Loss: 0.507 | Acc: 82.482%\n",
            "Train Epoch: 19 [10240/50000] Loss: 0.508 | Acc: 82.427%\n",
            "Train Epoch: 19 [11520/50000] Loss: 0.506 | Acc: 82.572%\n",
            "Train Epoch: 19 [12800/50000] Loss: 0.501 | Acc: 82.650%\n",
            "Train Epoch: 19 [14080/50000] Loss: 0.507 | Acc: 82.580%\n",
            "Train Epoch: 19 [15360/50000] Loss: 0.504 | Acc: 82.709%\n",
            "Train Epoch: 19 [16640/50000] Loss: 0.507 | Acc: 82.544%\n",
            "Train Epoch: 19 [17920/50000] Loss: 0.509 | Acc: 82.480%\n",
            "Train Epoch: 19 [19200/50000] Loss: 0.505 | Acc: 82.606%\n",
            "Train Epoch: 19 [20480/50000] Loss: 0.506 | Acc: 82.512%\n",
            "Train Epoch: 19 [21760/50000] Loss: 0.505 | Acc: 82.570%\n",
            "Train Epoch: 19 [23040/50000] Loss: 0.506 | Acc: 82.549%\n",
            "Train Epoch: 19 [24320/50000] Loss: 0.510 | Acc: 82.469%\n",
            "Train Epoch: 19 [25600/50000] Loss: 0.511 | Acc: 82.432%\n",
            "Train Epoch: 19 [26880/50000] Loss: 0.511 | Acc: 82.405%\n",
            "Train Epoch: 19 [28160/50000] Loss: 0.509 | Acc: 82.431%\n",
            "Train Epoch: 19 [29440/50000] Loss: 0.509 | Acc: 82.461%\n",
            "Train Epoch: 19 [30720/50000] Loss: 0.509 | Acc: 82.498%\n",
            "Train Epoch: 19 [32000/50000] Loss: 0.512 | Acc: 82.408%\n",
            "Train Epoch: 19 [33280/50000] Loss: 0.511 | Acc: 82.453%\n",
            "Train Epoch: 19 [34560/50000] Loss: 0.510 | Acc: 82.481%\n",
            "Train Epoch: 19 [35840/50000] Loss: 0.509 | Acc: 82.518%\n",
            "Train Epoch: 19 [37120/50000] Loss: 0.509 | Acc: 82.493%\n",
            "Train Epoch: 19 [38400/50000] Loss: 0.509 | Acc: 82.530%\n",
            "Train Epoch: 19 [39680/50000] Loss: 0.509 | Acc: 82.534%\n",
            "Train Epoch: 19 [40960/50000] Loss: 0.510 | Acc: 82.474%\n",
            "Train Epoch: 19 [42240/50000] Loss: 0.511 | Acc: 82.425%\n",
            "Train Epoch: 19 [43520/50000] Loss: 0.512 | Acc: 82.409%\n",
            "Train Epoch: 19 [44800/50000] Loss: 0.514 | Acc: 82.352%\n",
            "Train Epoch: 19 [46080/50000] Loss: 0.514 | Acc: 82.308%\n",
            "Train Epoch: 19 [47360/50000] Loss: 0.514 | Acc: 82.330%\n",
            "Train Epoch: 19 [48640/50000] Loss: 0.514 | Acc: 82.361%\n",
            "Train Epoch: 19 [31200/50000] Loss: 0.515 | Acc: 82.336%\n",
            "Test Epoch: 19 | Loss: 0.585 | Acc: 80.150%\n",
            "Train Epoch: 20 [0/50000] Loss: 0.535 | Acc: 78.125%\n",
            "Train Epoch: 20 [1280/50000] Loss: 0.509 | Acc: 83.239%\n",
            "Train Epoch: 20 [2560/50000] Loss: 0.505 | Acc: 83.259%\n",
            "Train Epoch: 20 [3840/50000] Loss: 0.518 | Acc: 82.636%\n",
            "Train Epoch: 20 [5120/50000] Loss: 0.507 | Acc: 82.812%\n",
            "Train Epoch: 20 [6400/50000] Loss: 0.492 | Acc: 83.333%\n",
            "Train Epoch: 20 [7680/50000] Loss: 0.494 | Acc: 83.338%\n",
            "Train Epoch: 20 [8960/50000] Loss: 0.495 | Acc: 83.308%\n",
            "Train Epoch: 20 [10240/50000] Loss: 0.490 | Acc: 83.536%\n",
            "Train Epoch: 20 [11520/50000] Loss: 0.495 | Acc: 83.448%\n",
            "Train Epoch: 20 [12800/50000] Loss: 0.497 | Acc: 83.284%\n",
            "Train Epoch: 20 [14080/50000] Loss: 0.495 | Acc: 83.397%\n",
            "Train Epoch: 20 [15360/50000] Loss: 0.498 | Acc: 83.290%\n",
            "Train Epoch: 20 [16640/50000] Loss: 0.505 | Acc: 82.985%\n",
            "Train Epoch: 20 [17920/50000] Loss: 0.508 | Acc: 82.907%\n",
            "Train Epoch: 20 [19200/50000] Loss: 0.511 | Acc: 82.849%\n",
            "Train Epoch: 20 [20480/50000] Loss: 0.513 | Acc: 82.754%\n",
            "Train Epoch: 20 [21760/50000] Loss: 0.510 | Acc: 82.835%\n",
            "Train Epoch: 20 [23040/50000] Loss: 0.509 | Acc: 82.838%\n",
            "Train Epoch: 20 [24320/50000] Loss: 0.506 | Acc: 82.927%\n",
            "Train Epoch: 20 [25600/50000] Loss: 0.504 | Acc: 82.999%\n",
            "Train Epoch: 20 [26880/50000] Loss: 0.502 | Acc: 83.057%\n",
            "Train Epoch: 20 [28160/50000] Loss: 0.502 | Acc: 82.989%\n",
            "Train Epoch: 20 [29440/50000] Loss: 0.502 | Acc: 83.009%\n",
            "Train Epoch: 20 [30720/50000] Loss: 0.501 | Acc: 83.026%\n",
            "Train Epoch: 20 [32000/50000] Loss: 0.501 | Acc: 83.030%\n",
            "Train Epoch: 20 [33280/50000] Loss: 0.501 | Acc: 83.046%\n",
            "Train Epoch: 20 [34560/50000] Loss: 0.501 | Acc: 83.043%\n",
            "Train Epoch: 20 [35840/50000] Loss: 0.502 | Acc: 83.013%\n",
            "Train Epoch: 20 [37120/50000] Loss: 0.502 | Acc: 83.030%\n",
            "Train Epoch: 20 [38400/50000] Loss: 0.502 | Acc: 83.002%\n",
            "Train Epoch: 20 [39680/50000] Loss: 0.502 | Acc: 83.008%\n",
            "Train Epoch: 20 [40960/50000] Loss: 0.501 | Acc: 83.022%\n",
            "Train Epoch: 20 [42240/50000] Loss: 0.500 | Acc: 83.056%\n",
            "Train Epoch: 20 [43520/50000] Loss: 0.501 | Acc: 83.014%\n",
            "Train Epoch: 20 [44800/50000] Loss: 0.502 | Acc: 82.975%\n",
            "Train Epoch: 20 [46080/50000] Loss: 0.504 | Acc: 82.916%\n",
            "Train Epoch: 20 [47360/50000] Loss: 0.504 | Acc: 82.926%\n",
            "Train Epoch: 20 [48640/50000] Loss: 0.504 | Acc: 82.909%\n",
            "Train Epoch: 20 [31200/50000] Loss: 0.504 | Acc: 82.912%\n",
            "Test Epoch: 20 | Loss: 0.771 | Acc: 74.500%\n",
            "Train Epoch: 21 [0/50000] Loss: 0.534 | Acc: 80.469%\n",
            "Train Epoch: 21 [1280/50000] Loss: 0.504 | Acc: 83.097%\n",
            "Train Epoch: 21 [2560/50000] Loss: 0.489 | Acc: 83.519%\n",
            "Train Epoch: 21 [3840/50000] Loss: 0.468 | Acc: 84.299%\n",
            "Train Epoch: 21 [5120/50000] Loss: 0.469 | Acc: 84.070%\n",
            "Train Epoch: 21 [6400/50000] Loss: 0.474 | Acc: 83.885%\n",
            "Train Epoch: 21 [7680/50000] Loss: 0.484 | Acc: 83.478%\n",
            "Train Epoch: 21 [8960/50000] Loss: 0.492 | Acc: 83.209%\n",
            "Train Epoch: 21 [10240/50000] Loss: 0.496 | Acc: 83.005%\n",
            "Train Epoch: 21 [11520/50000] Loss: 0.498 | Acc: 82.890%\n",
            "Train Epoch: 21 [12800/50000] Loss: 0.496 | Acc: 83.099%\n",
            "Train Epoch: 21 [14080/50000] Loss: 0.497 | Acc: 83.038%\n",
            "Train Epoch: 21 [15360/50000] Loss: 0.500 | Acc: 82.929%\n",
            "Train Epoch: 21 [16640/50000] Loss: 0.502 | Acc: 82.872%\n",
            "Train Epoch: 21 [17920/50000] Loss: 0.504 | Acc: 82.718%\n",
            "Train Epoch: 21 [19200/50000] Loss: 0.504 | Acc: 82.694%\n",
            "Train Epoch: 21 [20480/50000] Loss: 0.504 | Acc: 82.730%\n",
            "Train Epoch: 21 [21760/50000] Loss: 0.505 | Acc: 82.648%\n",
            "Train Epoch: 21 [23040/50000] Loss: 0.507 | Acc: 82.519%\n",
            "Train Epoch: 21 [24320/50000] Loss: 0.509 | Acc: 82.473%\n",
            "Train Epoch: 21 [25600/50000] Loss: 0.509 | Acc: 82.490%\n",
            "Train Epoch: 21 [26880/50000] Loss: 0.507 | Acc: 82.535%\n",
            "Train Epoch: 21 [28160/50000] Loss: 0.506 | Acc: 82.604%\n",
            "Train Epoch: 21 [29440/50000] Loss: 0.506 | Acc: 82.566%\n",
            "Train Epoch: 21 [30720/50000] Loss: 0.507 | Acc: 82.537%\n",
            "Train Epoch: 21 [32000/50000] Loss: 0.507 | Acc: 82.511%\n",
            "Train Epoch: 21 [33280/50000] Loss: 0.509 | Acc: 82.411%\n",
            "Train Epoch: 21 [34560/50000] Loss: 0.509 | Acc: 82.397%\n",
            "Train Epoch: 21 [35840/50000] Loss: 0.509 | Acc: 82.407%\n",
            "Train Epoch: 21 [37120/50000] Loss: 0.508 | Acc: 82.447%\n",
            "Train Epoch: 21 [38400/50000] Loss: 0.508 | Acc: 82.439%\n",
            "Train Epoch: 21 [39680/50000] Loss: 0.511 | Acc: 82.328%\n",
            "Train Epoch: 21 [40960/50000] Loss: 0.512 | Acc: 82.345%\n",
            "Train Epoch: 21 [42240/50000] Loss: 0.512 | Acc: 82.352%\n",
            "Train Epoch: 21 [43520/50000] Loss: 0.511 | Acc: 82.405%\n",
            "Train Epoch: 21 [44800/50000] Loss: 0.511 | Acc: 82.430%\n",
            "Train Epoch: 21 [46080/50000] Loss: 0.512 | Acc: 82.384%\n",
            "Train Epoch: 21 [47360/50000] Loss: 0.513 | Acc: 82.381%\n",
            "Train Epoch: 21 [48640/50000] Loss: 0.513 | Acc: 82.355%\n",
            "Train Epoch: 21 [31200/50000] Loss: 0.512 | Acc: 82.390%\n",
            "Test Epoch: 21 | Loss: 0.652 | Acc: 77.690%\n",
            "Train Epoch: 22 [0/50000] Loss: 0.557 | Acc: 83.594%\n",
            "Train Epoch: 22 [1280/50000] Loss: 0.507 | Acc: 82.955%\n",
            "Train Epoch: 22 [2560/50000] Loss: 0.485 | Acc: 83.631%\n",
            "Train Epoch: 22 [3840/50000] Loss: 0.488 | Acc: 83.543%\n",
            "Train Epoch: 22 [5120/50000] Loss: 0.495 | Acc: 83.136%\n",
            "Train Epoch: 22 [6400/50000] Loss: 0.508 | Acc: 82.751%\n",
            "Train Epoch: 22 [7680/50000] Loss: 0.502 | Acc: 83.081%\n",
            "Train Epoch: 22 [8960/50000] Loss: 0.503 | Acc: 82.956%\n",
            "Train Epoch: 22 [10240/50000] Loss: 0.508 | Acc: 82.764%\n",
            "Train Epoch: 22 [11520/50000] Loss: 0.510 | Acc: 82.615%\n",
            "Train Epoch: 22 [12800/50000] Loss: 0.509 | Acc: 82.611%\n",
            "Train Epoch: 22 [14080/50000] Loss: 0.506 | Acc: 82.651%\n",
            "Train Epoch: 22 [15360/50000] Loss: 0.506 | Acc: 82.606%\n",
            "Train Epoch: 22 [16640/50000] Loss: 0.509 | Acc: 82.502%\n",
            "Train Epoch: 22 [17920/50000] Loss: 0.510 | Acc: 82.508%\n",
            "Train Epoch: 22 [19200/50000] Loss: 0.509 | Acc: 82.554%\n",
            "Train Epoch: 22 [20480/50000] Loss: 0.507 | Acc: 82.648%\n",
            "Train Epoch: 22 [21760/50000] Loss: 0.509 | Acc: 82.607%\n",
            "Train Epoch: 22 [23040/50000] Loss: 0.507 | Acc: 82.657%\n",
            "Train Epoch: 22 [24320/50000] Loss: 0.506 | Acc: 82.673%\n",
            "Train Epoch: 22 [25600/50000] Loss: 0.506 | Acc: 82.680%\n",
            "Train Epoch: 22 [26880/50000] Loss: 0.507 | Acc: 82.601%\n",
            "Train Epoch: 22 [28160/50000] Loss: 0.507 | Acc: 82.565%\n",
            "Train Epoch: 22 [29440/50000] Loss: 0.508 | Acc: 82.566%\n",
            "Train Epoch: 22 [30720/50000] Loss: 0.507 | Acc: 82.628%\n",
            "Train Epoch: 22 [32000/50000] Loss: 0.505 | Acc: 82.632%\n",
            "Train Epoch: 22 [33280/50000] Loss: 0.505 | Acc: 82.606%\n",
            "Train Epoch: 22 [34560/50000] Loss: 0.505 | Acc: 82.570%\n",
            "Train Epoch: 22 [35840/50000] Loss: 0.507 | Acc: 82.559%\n",
            "Train Epoch: 22 [37120/50000] Loss: 0.507 | Acc: 82.568%\n",
            "Train Epoch: 22 [38400/50000] Loss: 0.507 | Acc: 82.584%\n",
            "Train Epoch: 22 [39680/50000] Loss: 0.507 | Acc: 82.561%\n",
            "Train Epoch: 22 [40960/50000] Loss: 0.508 | Acc: 82.482%\n",
            "Train Epoch: 22 [42240/50000] Loss: 0.507 | Acc: 82.562%\n",
            "Train Epoch: 22 [43520/50000] Loss: 0.506 | Acc: 82.602%\n",
            "Train Epoch: 22 [44800/50000] Loss: 0.505 | Acc: 82.630%\n",
            "Train Epoch: 22 [46080/50000] Loss: 0.505 | Acc: 82.620%\n",
            "Train Epoch: 22 [47360/50000] Loss: 0.505 | Acc: 82.644%\n",
            "Train Epoch: 22 [48640/50000] Loss: 0.504 | Acc: 82.689%\n",
            "Train Epoch: 22 [31200/50000] Loss: 0.504 | Acc: 82.718%\n",
            "Test Epoch: 22 | Loss: 0.652 | Acc: 78.000%\n",
            "Train Epoch: 23 [0/50000] Loss: 0.505 | Acc: 82.031%\n",
            "Train Epoch: 23 [1280/50000] Loss: 0.481 | Acc: 83.239%\n",
            "Train Epoch: 23 [2560/50000] Loss: 0.488 | Acc: 82.924%\n",
            "Train Epoch: 23 [3840/50000] Loss: 0.494 | Acc: 82.964%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# CBAM Module Definition\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        out = torch.cat([avg_out, max_out], dim=1)\n",
        "        out = self.conv1(out)\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.ca = ChannelAttention(in_channels, reduction)\n",
        "        self.sa = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x * self.ca(x)\n",
        "        out = out * self.sa(out)\n",
        "        return out\n",
        "\n",
        "# BasicBlock and Bottleneck with CBAM\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.cbam = CBAM(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU(inplace=True)(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.cbam(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = nn.ReLU(inplace=True)(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, shortcut_type='B'):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.cbam = CBAM(out_channels * self.expansion)\n",
        "\n",
        "        if shortcut_type == 'C' or (shortcut_type == 'B' and in_channels != out_channels * self.expansion):\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU(inplace=True)(self.bn1(self.conv1(x)))\n",
        "        out = nn.ReLU(inplace=True)(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out = self.cbam(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = nn.ReLU(inplace=True)(out)\n",
        "        return out\n",
        "\n",
        "# HybridResNet with CBAM\n",
        "class HybridResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(HybridResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(BasicBlock, 16, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 32, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, 64, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(Bottleneck, 128, 2, stride=2)\n",
        "        self.linear = nn.Linear(128 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = nn.ReLU(inplace=True)(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = nn.AvgPool2d(4)(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# Training and Testing Functions\n",
        "def train(epoch, net, trainloader, optimizer, criterion, device):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(inputs)}/{len(trainloader.dataset)}] '\n",
        "                  f'Loss: {train_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f}%')\n",
        "\n",
        "def test(epoch, net, testloader, criterion, device):\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print(f'Test Epoch: {epoch} | Loss: {test_loss/(batch_idx+1):.3f} | Acc: {100.*correct/total:.3f}%')\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "    net = HybridResNet(num_classes=10).to(device)\n",
        "    if device == 'cuda':\n",
        "        net = torch.nn.DataParallel(net)\n",
        "        cudnn.benchmark = True\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "\n",
        "    for epoch in range(0, 200):\n",
        "        train(epoch, net, trainloader, optimizer, criterion, device)\n",
        "        test(epoch, net, testloader, criterion, device)\n",
        "        scheduler.step()\n",
        "        if epoch % 50 == 0:\n",
        "            torch.save(net.state_dict(), f'HybridResNet_epoch_{epoch}.pth')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSc18JEf/09AfDaEP0ZHvp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}