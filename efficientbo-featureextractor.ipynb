{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrutadeo-22/resnet/blob/main/efficientbo-featureextractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIk7B0-GL2w5",
        "outputId": "f06bfbd9-cc80-4798-8e52-12abbed8b72d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 61.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.4309\n",
            "Epoch 1, Test Accuracy: 69.17%\n",
            "Epoch 2, Loss: 0.8706\n",
            "Epoch 2, Test Accuracy: 75.17%\n",
            "Epoch 3, Loss: 0.7205\n",
            "Epoch 3, Test Accuracy: 77.90%\n",
            "Epoch 4, Loss: 0.6338\n",
            "Epoch 4, Test Accuracy: 80.22%\n",
            "Epoch 5, Loss: 0.5748\n",
            "Epoch 5, Test Accuracy: 76.99%\n",
            "Epoch 6, Loss: 0.6124\n",
            "Epoch 6, Test Accuracy: 79.57%\n",
            "Epoch 7, Loss: 0.5403\n",
            "Epoch 7, Test Accuracy: 82.38%\n",
            "Epoch 8, Loss: 0.4890\n",
            "Epoch 8, Test Accuracy: 82.93%\n",
            "Epoch 9, Loss: 0.4838\n",
            "Epoch 9, Test Accuracy: 77.65%\n",
            "Epoch 10, Loss: 0.6129\n",
            "Epoch 10, Test Accuracy: 80.82%\n",
            "Test Accuracy: 81.12%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import efficientnet_b0\n",
        "\n",
        "# Define CBAM module\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, reduction_ratio=16, kernel_size=7):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // reduction_ratio, kernel_size=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels // reduction_ratio, channels, kernel_size=1, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Channel attention\n",
        "        ca = self.channel_attention(x)\n",
        "        x = x * ca\n",
        "\n",
        "        # Spatial attention\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        sa = torch.cat([avg_out, max_out], dim=1)\n",
        "        sa = self.spatial_attention(sa)\n",
        "        x = x * sa\n",
        "\n",
        "        return x\n",
        "\n",
        "# Define BasicBlock and Bottleneck for ResNet\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = torch.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "# Define the HybridResNet\n",
        "class HybridResNetWithEfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(HybridResNetWithEfficientNet, self).__init__()\n",
        "        self.efficient_net = efficientnet_b0(pretrained=True)\n",
        "\n",
        "        # Remove the classification head from EfficientNet-B0\n",
        "        self.efficient_net_features = nn.Sequential(*list(self.efficient_net.children())[:-2])\n",
        "        self.in_channels = 1280\n",
        "\n",
        "        # Define ResNet layers with CBAM\n",
        "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, 2, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
        "        self.layer4 = self._make_layer(Bottleneck, 512, 2, stride=2)\n",
        "\n",
        "        self.cbam = CBAM(512 * Bottleneck.expansion)\n",
        "\n",
        "        # Final classification layer\n",
        "        self.linear = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.efficient_net_features(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.cbam(out)\n",
        "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "# Data loading\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Training and evaluation\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HybridResNetWithEfficientNet(num_classes=10).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with accuracy evaluation\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Evaluate accuracy after each epoch\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Epoch {epoch + 1}, Test Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Test Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkLDuEluPUNg",
        "outputId": "a02f38a9-4b99-40b2-cf71-73e9bbb09233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomEfficientResNet(\n",
            "  (initial_conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (block1): WideResNetBlock(\n",
            "    (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (shortcut): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (block2): AggregatedResNetBlock(\n",
            "    (convs): ModuleList(\n",
            "      (0-31): 32 x Conv2d(64, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (block3): CBAM(\n",
            "    (se_block): SEBlock(\n",
            "      (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (spatial_attention): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "  )\n",
            "  (block4): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "    (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (block5): CBAM(\n",
            "    (se_block): SEBlock(\n",
            "      (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (spatial_attention): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "  )\n",
            "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Swish activation function\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "# Squeeze-and-Excitation (SE) Block\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
        "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        scale = F.adaptive_avg_pool2d(x, 1)\n",
        "        scale = F.relu(self.fc1(scale))\n",
        "        scale = torch.sigmoid(self.fc2(scale))\n",
        "        return x * scale\n",
        "\n",
        "# Convolutional Block Attention Module (CBAM)\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.se_block = SEBlock(in_channels, reduction)\n",
        "        self.spatial_attention = nn.Conv2d(2, 1, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Channel Attention\n",
        "        x = self.se_block(x)\n",
        "\n",
        "        # Spatial Attention\n",
        "        max_pool = torch.max(x, dim=1, keepdim=True).values\n",
        "        avg_pool = torch.mean(x, dim=1, keepdim=True)\n",
        "        spatial_attention = torch.cat([max_pool, avg_pool], dim=1)\n",
        "        spatial_attention = torch.sigmoid(self.spatial_attention(spatial_attention))\n",
        "\n",
        "        return x * spatial_attention\n",
        "\n",
        "# Depthwise Separable Convolution\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x)\n",
        "\n",
        "# Wide ResNet Block\n",
        "class WideResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(WideResNetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        return F.relu(out)\n",
        "\n",
        "# Aggregated ResNet Block\n",
        "class AggregatedResNetBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, cardinality=32, stride=1):\n",
        "        super(AggregatedResNetBlock, self).__init__()\n",
        "        self.split_channels = out_channels // cardinality\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels, self.split_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "            for _ in range(cardinality)\n",
        "        ])\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        split_outputs = [conv(x) for conv in self.convs]\n",
        "        out = torch.cat(split_outputs, dim=1)\n",
        "        out = self.bn(out)\n",
        "        return F.relu(out)\n",
        "\n",
        "# Custom Model integrating EfficientNet ideas, CBAM, Wide ResNet, and Aggregated ResNet\n",
        "class CustomEfficientResNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomEfficientResNet, self).__init__()\n",
        "        self.initial_conv = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.block1 = WideResNetBlock(32, 64, stride=1)\n",
        "        self.block2 = AggregatedResNetBlock(64, 128, cardinality=32, stride=2)\n",
        "        self.block3 = CBAM(128)\n",
        "        self.block4 = DepthwiseSeparableConv(128, 256, stride=2)\n",
        "        self.block5 = CBAM(256)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn(self.initial_conv(x)))\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = CustomEfficientResNet(num_classes=10)\n",
        "print(model)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6ER/t5x86f4r0NBjAXgN+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}